{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTQdwWbq5Fvj"
      },
      "source": [
        "## Морфология\n",
        "#### План семинара:\n",
        "\n",
        "1. Mystem\n",
        "2. Pymorphy\n",
        "3. NLTK\n",
        "4. SpaCy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfvPBMcK5Fvl"
      },
      "source": [
        "Нужные пакеты для этого семинара:\n",
        "\n",
        "```python\n",
        "pip install pymystem3\n",
        "pip install pymorphy2\n",
        "pip install nltk\n",
        "pip install spacy\n",
        "```\n",
        "\n",
        "Если вы хотите побыстрее и у вас Linux или Mac\n",
        "\n",
        "``pip install pymorphy2[fast]``\n",
        "\n",
        "Если вы работаете с Python версии 3.11+, то устанавливайте `pymorphy3`. Это то же самое, но поддерживаются более новые версии Python. Если вы работаете в Google Colab, то он на версии 3.10.\n",
        "\n",
        "```python\n",
        "!pip install pymorphy3 --q\n",
        "\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dld-D_6G5Fvn"
      },
      "source": [
        "### Mystem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7YKvRur5Fvm"
      },
      "source": [
        "Mystem $-$ это свободно распространяемый морфологический анализатор для русского языка с закрытым исходным кодом.\n",
        "\n",
        "My-stem значит my stemmer, стемминг $-$ это разбиение формы на основу и флексию. На самом деле Mystem может гораздо больше: устанавливать словарную форму слова, определять часть речи и грамматическую форму слова. В последних версиях Mystem умеет и выбирать из нескольких возможных грамматических разборов один, наиболее верный.\n",
        "\n",
        "У Mystem нет графического оконного интерфейса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALQxwR__5Fvr"
      },
      "source": [
        "Можно запускать mystem через консоль (см. [документацию](https://yandex.ru/dev/mystem) и про запуск [тут](https://irmn.space/?go=all/lemmatizaciya-zaprosov-v-mystem/)), а можно с помощью специального модуля, **pymystem3**. Это проще и удобнее, потому что с тем, что выдаёт mystem, можно сразу работать как с питоновскими структурами данных. Но медленнее. Иногда гораздо-гораздо медленнее, чем разметить один файл mystem'ом сразу."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pymystem3 --q"
      ],
      "metadata": {
        "id": "_9fSVMQzrNGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQMgcBAW5Fvr",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "m_stem = Mystem()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxPL8r9W5Fvr"
      },
      "source": [
        "Небходимо создать экземпляр класса `Mystem`. У него есть два метода:\n",
        "\n",
        "* `lemmatize`, возвращающий список лемм,\n",
        "* `analyze`, возвращающий полные разборы в виде словаря.\n",
        "\n",
        "Возьмем небольшой текст и опробуем на нем эти два метода:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVwJQpvm5Fvr"
      },
      "outputs": [],
      "source": [
        "text = '''Но не становится ли событие тем значительнее и исключительнее,\n",
        "чем большее число случайностей приводит к нему?\n",
        "Лишь случайность может предстать перед нами как послание.\n",
        "Все, что происходит по необходимости, что ожидаемо, что повторяется всякий день, то немо.\n",
        "Лишь случайность о чем-то говорит нам. Мы стремимся прочесть ее,\n",
        "как читают цыганки по узорам, начертанным кофейной гущей на дне чашки.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx6nJImD5Fvs",
        "outputId": "fe91f09e-a627-4ec6-94ab-10d3ae96feb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['тем', ' ', 'значительный', ' ', 'и', ' ', 'исключительный', ',', 'чем', ' ']"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmas = m_stem.lemmatize(text)\n",
        "lemmas[10:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mWTwtCR5Fvs"
      },
      "source": [
        "Можно собрать лемматизированный текст обратно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or3WZysj5Fvs",
        "outputId": "7d66a33a-4364-42cc-c007-0456c1530ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "но не становиться ли событие тем значительный и исключительный,чем больший число случайность приводить к он? лишь случайность мочь представать перед мы как послание. все, что происходить по необходимость, что ожидать, что повторяться всякий день, то немо. лишь случайность о что-то говорить мы. мы стремиться прочитывать она, как читать цыганка по узор, начертать кофейный гуща на дно чашка.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(''.join(lemmas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5MOolzG5Fvs"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnGhKM2w5Fvs",
        "outputId": "9678a3de-0b29-449d-e75e-e0f3474ed60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'analysis': [{'gr': 'CONJ=', 'lex': 'но', 'wt': 0.9998906299}], 'text': 'Но'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'PART=', 'lex': 'не', 'wt': 1}], 'text': 'не'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'V,нп=непрош,ед,изъяв,3-л,несов',\n",
            "                'lex': 'становиться',\n",
            "                'wt': 1}],\n",
            "  'text': 'становится'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'PART=', 'lex': 'ли', 'wt': 0.7719288688}], 'text': 'ли'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'S,сред,неод=(вин,ед|им,ед)', 'lex': 'событие', 'wt': 1}],\n",
            "  'text': 'событие'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'CONJ=', 'lex': 'тем', 'wt': 0.0857739759}],\n",
            "  'text': 'тем'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'A=срав', 'lex': 'значительный', 'wt': 0.2062520859}],\n",
            "  'text': 'значительнее'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'CONJ=', 'lex': 'и', 'wt': 0.9999770357}], 'text': 'и'},\n",
            " {'text': ' '},\n",
            " {'analysis': [{'gr': 'A=срав', 'lex': 'исключительный', 'wt': 1}],\n",
            "  'text': 'исключительнее'},\n",
            " {'text': ','},\n",
            " {'analysis': [{'gr': 'CONJ=', 'lex': 'чем', 'wt': 0.8023791472}],\n",
            "  'text': 'чем'},\n",
            " {'text': ' '}]\n"
          ]
        }
      ],
      "source": [
        "ana = m_stem.analyze(text)\n",
        "pprint(ana[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20I2B4BZ5Fvt"
      },
      "source": [
        "Разбор для каждого слова является элементом массива:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqi6TcWR5Fvt",
        "outputId": "a05ea719-b394-419b-d6d6-c7ae025e72b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}], 'text': 'Но'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'становиться', 'wt': 1, 'gr': 'V,нп=непрош,ед,изъяв,3-л,несов'}], 'text': 'становится'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'ли', 'wt': 0.7719288688, 'gr': 'PART='}], 'text': 'ли'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'событие', 'wt': 1, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'событие'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'тем', 'wt': 0.0857739759, 'gr': 'CONJ='}], 'text': 'тем'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'значительный', 'wt': 0.2062520859, 'gr': 'A=срав'}], 'text': 'значительнее'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
            "{'text': ' '}\n",
            "{'analysis': [{'lex': 'исключительный', 'wt': 1, 'gr': 'A=срав'}], 'text': 'исключительнее'}\n",
            "{'text': ','}\n",
            "{'analysis': [{'lex': 'чем', 'wt': 0.8023791472, 'gr': 'CONJ='}], 'text': 'чем'}\n",
            "{'text': ' '}\n"
          ]
        }
      ],
      "source": [
        "for word in ana[:20]:\n",
        "    print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhhVeu895Fvt"
      },
      "source": [
        "В этом разборе в поле `text` можно найти исходное слова, а в поле `analysis` (которого может и не быть) $-$ грамматические характеристики и леммы.\n",
        "\n",
        "В грамматическом разборе знаком `=` отделяются изменяемые характеристики от неизменяемых. Знаком `|` отделяются омонимичные разборы.\n",
        "\n",
        "Достанем все части речи:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOeLkZGe5Fvt",
        "outputId": "2721a1bd-17f3-4097-dc14-1e2d0bc8f677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Но CONJ\n",
            "не PART\n",
            "становится V\n",
            "ли PART\n",
            "событие S\n",
            "тем CONJ\n",
            "значительнее A\n",
            "и CONJ\n",
            "исключительнее A\n",
            "чем CONJ\n"
          ]
        }
      ],
      "source": [
        "for word in ana[:20]:\n",
        "    if 'analysis' in word:\n",
        "        gr = word['analysis'][0]['gr']\n",
        "        pos = gr.split('=')[0].split(',')[0]\n",
        "        print(word['text'], pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE5H9OGH5Fvt"
      },
      "source": [
        "#### Саммари\n",
        "\n",
        "**Достоинства Mystem'a:**\n",
        "\n",
        "- хорошее качество разбора\n",
        "- по умолчанию разрешается частеречная омонимия (внутри части речи остается)\n",
        "- при разборе учитывается контекст\n",
        "- совместим с разметкой НКРЯ\n",
        "\n",
        "**Недостатки Mystem'a:**\n",
        "\n",
        "- медленный\n",
        "- `analyze` возвращает неудобный JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y0GERqF5Fvu"
      },
      "source": [
        "### Pymorphy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKjwkRqP5Fvu"
      },
      "source": [
        "Может делать то же, что и `pymystem3`, и даже больше: изменять слова в нужную форму (спрягать и склонять). При этом `pymorphy2` справляется и с незнакомыми словами.\n",
        "\n",
        "[**Документация**](https://pymorphy2.readthedocs.io/en/latest/)\n",
        "\n",
        "Для работы точно так же надо создать экземпляр класса `MorphAnalyzer`. Рекомендуется создать один экземпляр и дальше с ним и работать, поскольку он занимает достаточно много памяти, и если создать несколько экземпляров анализаторов, то они будут тормозить программу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_79P2wfHvn4"
      },
      "outputs": [],
      "source": [
        "# !pip install pymorphy2 --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03_xyOm15Fvu"
      },
      "outputs": [],
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "morph = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGEqYOhT5Fvu"
      },
      "source": [
        "Разбор слова делается при помощи метода `parse`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiR-kiyi5Fvu",
        "outputId": "d443bee9-98fe-4199-ba47-b0e82b8ed719"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parse(word='стекла', tag=OpencorporaTag('NOUN,inan,neut sing,gent'), normal_form='стекло', score=0.828282, methods_stack=((DictionaryAnalyzer(), 'стекла', 157, 1),)),\n",
              " Parse(word='стёкла', tag=OpencorporaTag('NOUN,inan,neut plur,nomn'), normal_form='стекло', score=0.080808, methods_stack=((DictionaryAnalyzer(), 'стёкла', 157, 6),)),\n",
              " Parse(word='стёкла', tag=OpencorporaTag('NOUN,inan,neut plur,accs'), normal_form='стекло', score=0.080808, methods_stack=((DictionaryAnalyzer(), 'стёкла', 157, 9),)),\n",
              " Parse(word='стекла', tag=OpencorporaTag('VERB,perf,intr femn,sing,past,indc'), normal_form='стечь', score=0.010101, methods_stack=((DictionaryAnalyzer(), 'стекла', 1015, 2),))]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ana = morph.parse('стекла')\n",
        "ana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu009Wvw5Fvu"
      },
      "source": [
        "Как видно, анализатор вернул все возможные разборы этого слова, отранжировав их по вероятности.\n",
        "\n",
        "У каждого разбора есть атрибуты:\n",
        "* исходное слово,\n",
        "* тэг,\n",
        "* лемма,\n",
        "* вероятность разбора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JJRNkVz5Fvu",
        "outputId": "49640e53-ac73-45c0-8e5c-20a3fc16cbe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Слово: стекла\n",
            "Тэг: NOUN,inan,neut sing,gent\n",
            "Лемма: стекло\n",
            "Вероятность: 0.828282\n"
          ]
        }
      ],
      "source": [
        "first = ana[0]  # первый разбор\n",
        "print('Слово:', first.word)\n",
        "print('Тэг:', first.tag)\n",
        "print('Лемма:', first.normal_form)\n",
        "print('Вероятность:', first.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j8Brqrk5Fvv"
      },
      "source": [
        "Для каждого разбора можно получить лемму и всю информацию о ней (т.е. еще один разбор, только уже для леммы):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgCj_B4P5Fvv",
        "outputId": "ce02fc14-ef67-4ed6-ef54-b67c4e658597"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parse(word='стекло', tag=OpencorporaTag('NOUN,inan,neut sing,nomn'), normal_form='стекло', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стекло', 157, 0),))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first.normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th6n7d6Y5Fvv",
        "outputId": "e281a695-4f55-47dc-a662-631822866071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Разбор слова:  Parse(word='стекла', tag=OpencorporaTag('VERB,perf,intr femn,sing,past,indc'), normal_form='стечь', score=0.010101, methods_stack=((DictionaryAnalyzer(), 'стекла', 1015, 2),))\n",
            "\n",
            "Разбор леммы:  Parse(word='стечь', tag=OpencorporaTag('INFN,perf,intr'), normal_form='стечь', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стечь', 1015, 0),))\n"
          ]
        }
      ],
      "source": [
        "last = ana[-1] # последний разбор\n",
        "print('Разбор слова: ', last)\n",
        "print()\n",
        "print('Разбор леммы: ', last.normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWsyuI3K5Fvv"
      },
      "source": [
        "Если распечатать тег разбора, то может показаться, что это строка:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2OdesUj5Fvv",
        "outputId": "3690909c-c905-423e-de1f-adc113567875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOUN,inan,neut sing,gent\n"
          ]
        }
      ],
      "source": [
        "first = ana[0]  # первый разбор\n",
        "print(first.tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixIAxSt5Fvw"
      },
      "source": [
        "Но на самом деле это объект класса `OpencorporaTag`, так что некоторые вещи, которые можно делать со строками, с тэгами делать нельзя. А некоторые все-таки можно.\n",
        "\n",
        "Например, можно проверить, есть ли какая-то граммема в теге:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXhRlU6l5Fvx",
        "outputId": "c7076163-9ccc-4e06-914c-af096747646a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'NOUN' in first.tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9rk8Mr_5Fvx",
        "outputId": "8c3ab427-de51-4fdd-fa37-b5844f604c0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'VERB' in first.tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzEBAGHm5Fvx",
        "outputId": "53ab7588-45e0-4ee5-e2ff-12194fddd08f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{'NOUN', 'inan'} in first.tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0O67-7J5Fvy"
      },
      "source": [
        "Из каждого тега можно достать более дробную информацию. Если граммема есть в разборе, то вернется ее значение, если ее нет, то вернется `None`.\n",
        "\n",
        "| Граммема                | Значение                                  |\n",
        "|-------------------------|-------------------------------------------|\n",
        "| `p.tag.POS`             | Part of Speech, часть речи                |\n",
        "| `p.tag.animacy`         | одушевленность                            |\n",
        "| `p.tag.aspect`          | вид: совершенный или несовершенный        |\n",
        "| `p.tag.case`            | падеж                                     |\n",
        "| `p.tag.gender`          | род (мужской, женский, средний)           |\n",
        "| `p.tag.involvement`     | включенность говорящего в действие        |\n",
        "| `p.tag.mood`            | наклонение (повелительное, изъявительное) |\n",
        "| `p.tag.number`          | число (единственное, множественное)       |\n",
        "| `p.tag.person`          | лицо (1, 2, 3)                            |\n",
        "| `p.tag.tense`           | время (настоящее, прошедшее, будущее)     |\n",
        "| `p.tag.transitivity`    | переходность (переходный, непереходный)   |\n",
        "| `p.tag.voice`           | залог (действительный, страдательный)     |\n",
        "| и др.                   |                                           |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv4EJFTS5Fvy",
        "outputId": "2c553c8c-82df-4538-f40f-95c09d37f583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VERB,perf,intr femn,sing,past,indc\n",
            "Время:  past\n",
            "Падеж:  None\n"
          ]
        }
      ],
      "source": [
        "print(last.tag)\n",
        "print('Время: ', last.tag.tense)\n",
        "print('Падеж: ', last.tag.case)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dhAg82t5Fvy"
      },
      "source": [
        "Список граммем, которые используются в модуле, находится [здесь](https://pymorphy2.readthedocs.io/en/latest/user/grammemes.html).\n",
        "\n",
        "Если искать какую-то граммему, которой нет в этом списке, возникнет ошибка.\n",
        "\n",
        "Можно получить строку с кириллическими обозначениями граммем:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kvs3_S1G5Fvy",
        "outputId": "1ea827f7-782d-4e10-ba51-56cbe2cfc93b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'СУЩ,неод,ср ед,рд'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first.tag.cyr_repr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARwv2PQw5Fvz"
      },
      "source": [
        "**Словоизменение**\n",
        "\n",
        "Если у нас есть разбор слова, то мы можем это слово поставить в другую форму с помощью функции `inflect`. Эта функция получает на вход множество граммем и пытается применить их к нашему разбору."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prog = morph.parse('программирую')[0]"
      ],
      "metadata": {
        "id": "6HW8V7Kzsjbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7BC41LT5Fvz",
        "outputId": "0c87cb68-c105-4832-bf8b-9c98880e91cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parse(word='программируем', tag=OpencorporaTag('VERB,impf,tran plur,1per,pres,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программируем', 171, 2),))"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prog.inflect({'plur'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js2oquwv5Fvz",
        "outputId": "5570e82f-8582-45b1-a7cb-866e2bf2fb1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parse(word='программировали', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программировали', 171, 10),))"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prog.inflect({'plur', 'past'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDhzS0775Fv0",
        "outputId": "4a59933b-eefa-4b78-b519-84744faf456a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parse(word='программировал', tag=OpencorporaTag('VERB,impf,tran masc,sing,past,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программировал', 171, 7),))"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prog.inflect({'past'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aTHms7zh5Fv0",
        "outputId": "65d5551e-351d-4df4-f147-797381d897e7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'программировала'"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prog.inflect({'past', 'femn'})[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-0i_toJ5Fv0"
      },
      "source": [
        "**Формы слова**\n",
        "\n",
        "С помощью атрибута `lexeme` можно получить массив всех форм слова:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P38hIOfO5Fv0",
        "outputId": "b42da74f-0892-47f6-d9ec-f5d3a1e74332"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parse(word='программировать', tag=OpencorporaTag('INFN,impf,tran'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программировать', 171, 0),)),\n",
              " Parse(word='программирую', tag=OpencorporaTag('VERB,impf,tran sing,1per,pres,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программирую', 171, 1),)),\n",
              " Parse(word='программируем', tag=OpencorporaTag('VERB,impf,tran plur,1per,pres,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программируем', 171, 2),)),\n",
              " Parse(word='программируешь', tag=OpencorporaTag('VERB,impf,tran sing,2per,pres,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программируешь', 171, 3),)),\n",
              " Parse(word='программируете', tag=OpencorporaTag('VERB,impf,tran plur,2per,pres,indc'), normal_form='программировать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'программируете', 171, 4),))]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prog.lexeme[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOavcpUR5Fv1"
      },
      "source": [
        "**Согласование слов с числительными**\n",
        "\n",
        "Из документации:\n",
        "\n",
        "> Слово нужно ставить в разные формы в зависимости от числительного, к которому оно относится.<br>Например: “1 бутявка”, “2 бутявки”, “5 бутявок” Для этих целей используйте метод `Parse.make_agree_with_number()`:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws1WJgiB5Fv1"
      },
      "outputs": [],
      "source": [
        "butyavka = morph.parse('бутявка')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uuy25eWC5Fv1",
        "outputId": "a75cd85e-27bc-4050-e7fc-ae489ab490a8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'бутявка'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "butyavka.make_agree_with_number(1).word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "C1PqtRSH5Fv2",
        "outputId": "b1894c48-55b3-4e4b-b67d-0ef189e190fa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'бутявки'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "butyavka.make_agree_with_number(2).word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "42I0DJct5Fv3",
        "outputId": "6979a8a6-75fc-40de-a9e2-cd368621bec9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'бутявок'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "butyavka.make_agree_with_number(5).word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKZjCxV3K84R"
      },
      "source": [
        "**Приколы**\n",
        "\n",
        "При помощи `pymorphy2` даже можно делать самое простенькое NER (*Named Entity Recognition*, распознавание именованных сущностей), так как в разборах есть теги:\n",
        "* `Geox`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9sHHuKZK7rG",
        "outputId": "88ed1901-4e81-43c2-e7fc-ad8a92d8e85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parse(word='санкт-петербург', tag=OpencorporaTag('NOUN,inan,masc,Geox sing,nomn'), normal_form='санкт-петербург', score=0.615384, methods_stack=((DictionaryAnalyzer(), 'санкт-петербург', 74, 0),)), Parse(word='санкт-петербург', tag=OpencorporaTag('NOUN,inan,masc,Geox sing,accs'), normal_form='санкт-петербург', score=0.384615, methods_stack=((DictionaryAnalyzer(), 'санкт-петербург', 74, 3),))]\n",
            "[Parse(word='москва', tag=OpencorporaTag('NOUN,inan,femn,Sgtm,Geox sing,nomn'), normal_form='москва', score=1.0, methods_stack=((DictionaryAnalyzer(), 'москва', 36, 0),))]\n"
          ]
        }
      ],
      "source": [
        "print(morph.parse('Санкт-Петербург'))\n",
        "print(morph.parse('Москва'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dejvL4RpMEfx"
      },
      "source": [
        "* `Surn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JluevIf6Ltvw",
        "outputId": "27948409-a35e-4ef3-ba0a-e288f7d1094b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parse(word='набоков', tag=OpencorporaTag('NOUN,anim,masc,Sgtm,Surn sing,nomn'), normal_form='набоков', score=1.0, methods_stack=((DictionaryAnalyzer(), 'набоков', 37, 0),))]\n",
            "[Parse(word='чичиков', tag=OpencorporaTag('NOUN,anim,masc,Sgtm,Surn sing,nomn'), normal_form='чичиков', score=1.0, methods_stack=((DictionaryAnalyzer(), 'чичиков', 37, 0),))]\n"
          ]
        }
      ],
      "source": [
        "print(morph.parse('Набоков'))\n",
        "print(morph.parse('Чичиков'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNtg4swMHIF"
      },
      "source": [
        "* `Name`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpUB7o1JLzdT",
        "outputId": "843e91b9-ebec-4875-9278-d2936c2a90a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parse(word='владимир', tag=OpencorporaTag('NOUN,anim,masc,Name sing,nomn'), normal_form='владимир', score=0.979452, methods_stack=((DictionaryAnalyzer(), 'владимир', 27, 0),)), Parse(word='владимир', tag=OpencorporaTag('NOUN,inan,masc,Geox sing,nomn'), normal_form='владимир', score=0.013698, methods_stack=((DictionaryAnalyzer(), 'владимир', 33, 0),)), Parse(word='владимир', tag=OpencorporaTag('NOUN,inan,masc,Geox sing,accs'), normal_form='владимир', score=0.006849, methods_stack=((DictionaryAnalyzer(), 'владимир', 33, 3),))]\n",
            "[Parse(word='павел', tag=OpencorporaTag('NOUN,anim,masc,Name sing,nomn'), normal_form='павел', score=1.0, methods_stack=((DictionaryAnalyzer(), 'павел', 2371, 0),))]\n"
          ]
        }
      ],
      "source": [
        "print(morph.parse('Владимир'))\n",
        "print(morph.parse('Павел'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bj9H5lW5Fv3"
      },
      "source": [
        "#### Саммари\n",
        "\n",
        "**Достоинства Pymorphy:**\n",
        "\n",
        "- умеет составлять разборы, находить лемму, склонять и спрягать\n",
        "- генерирует гипотезы для незнакомых слов\n",
        "- написан полностью на питоне и быстрее, чем Mystem (и есть ускоренная версия с вставками на C++)\n",
        "- может работать с украинским языком (но словари нужно отдельно устанавливать)\n",
        "\n",
        "**Недостатки Pymorphy:**\n",
        "\n",
        "- качество хуже, чем у Mystem\n",
        "- работает только на уровне отдельных слов (и естественно, не учитывает контекст)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xws2raTl5Fv3"
      },
      "source": [
        "**Небольшой хак**\n",
        "\n",
        "Pymorphy и так работает очень быстро, но можно еще быстрее, если мы будем сохранять разборы для очень популярных слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5M3mych5Fv4"
      },
      "outputs": [],
      "source": [
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiZGOB2f5Fv4"
      },
      "outputs": [],
      "source": [
        "with open('nabokov.txt', encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "text = [word.lower().strip(punctuation) for word in text.split()]\n",
        "text = [word for word in text if word != '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGul5U4s5Fv4",
        "outputId": "9224cf39-1782-4556-c3bd-81098f960217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.87 s ± 1.09 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "lemmas = []\n",
        "\n",
        "for word in text:\n",
        "    lemmas.append(morph.parse(word)[0].normal_form)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCE1PhFp5Fv5",
        "outputId": "47ecd33b-be86-4ed5-a8ad-9d290f57c99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.87 s ± 511 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "lemmas = []\n",
        "known_words = {}\n",
        "\n",
        "for word in text:\n",
        "    if word in known_words:\n",
        "        lemmas.append(known_words[word])\n",
        "    else:\n",
        "        result = morph.parse(word)[0].normal_form\n",
        "        lemmas.append(result)\n",
        "        known_words[word] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3LWsrWx5Fv5"
      },
      "source": [
        "Мы просто запоминаем леммы и поэтому не парсим слово каждый раз, а берем из быстрого хранилища готовый результат. Это может серьезно загружать память (при больших объемах), но значительно сократит время работы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q-BGMZd5Fv7"
      },
      "source": [
        "### NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR2Ea8285Fv7"
      },
      "source": [
        "Это уже не просто морфологический анализатор, а целая NLP библиотека!\n",
        "\n",
        "[**Документация**](https://www.nltk.org/)\n",
        "\n",
        "Что мы тут можем делать? Можем токенизировать какой-нибудь текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hgq-KgI5Fv7"
      },
      "outputs": [],
      "source": [
        "text = '''\n",
        "В. В. Набоков \"Как я люблю тебя\".\n",
        "\n",
        "Такой зеленый, серый, то есть\n",
        "весь заштрихованный дождем,\n",
        "и липовое, столь густое,\n",
        "что я перенести - уйдем!\n",
        "Уйдем и этот сад оставим\n",
        "и дождь, кипящий на тропах\n",
        "между тяжелыми цветами,\n",
        "целующими липкий прах.\n",
        "Уйдем, уйдем, пока не поздно,\n",
        "скорее, под плащом, домой,\n",
        "пока еще ты не опознан,\n",
        "безумный мой, безумный мой!\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWFeuroE5Fv7",
        "outputId": "45e9df9b-22aa-4614-99b6-39e263565cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXNUSKSWJbnC",
        "outputId": "289dea14-c0ab-4099-bce1-32c51c34c6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['В.', 'В.', 'Набоков', '``', 'Как', 'я', 'люблю', 'тебя', \"''\", '.', 'Такой', 'зеленый', ',', 'серый', ',', 'то', 'есть', 'весь', 'заштрихованный', 'дождем', ',', 'и', 'липовое', ',', 'столь', 'густое', ',', 'что', 'я', 'перенести', '-', 'уйдем', '!', 'Уйдем', 'и', 'этот', 'сад', 'оставим', 'и', 'дождь', ',', 'кипящий', 'на', 'тропах', 'между', 'тяжелыми', 'цветами', ',', 'целующими', 'липкий', 'прах', '.', 'Уйдем', ',', 'уйдем', ',', 'пока', 'не', 'поздно', ',', 'скорее', ',', 'под', 'плащом', ',', 'домой', ',', 'пока', 'еще', 'ты', 'не', 'опознан', ',', 'безумный', 'мой', ',', 'безумный', 'мой', '!']\n",
            "CPU times: user 960 µs, sys: 0 ns, total: 960 µs\n",
            "Wall time: 953 µs\n"
          ]
        }
      ],
      "source": [
        "%time print(word_tokenize(text, language='russian'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-m5HSmj5Fv8"
      },
      "source": [
        "Можем разделить текст на предложения (сплиттинг):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12W6cHEVJiOC"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX3GolHF5Fv8",
        "outputId": "86a7b7fc-44fe-41bb-c6f8-a6a5df72beb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nВ. В. Набоков \"Как я люблю тебя\".',\n",
              " 'Такой зеленый, серый, то есть\\nвесь заштрихованный дождем,\\nи липовое, столь густое,\\nчто я перенести - уйдем!',\n",
              " 'Уйдем и этот сад оставим\\nи дождь, кипящий на тропах\\nмежду тяжелыми цветами,\\nцелующими липкий прах.',\n",
              " 'Уйдем, уйдем, пока не поздно,\\nскорее, под плащом, домой,\\nпока еще ты не опознан,\\nбезумный мой, безумный мой!']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "sent_tokenize(text, language='russian')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87izxJQ5Fv8"
      },
      "source": [
        "NLTK может удалять стоп слова. Стоп-слова - это высокочастотные союзы, предлоги и другие служебные части речи, которые не дают нам никакой информации о конкретном тексте. В NLTK есть готовые списки стоп-слов (да-да, и для русского тоже есть)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0BvE2saJkLh",
        "outputId": "9c155126-ec0c-4d08-acbf-7de763dd337f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oAoLVlH5Fv8",
        "outputId": "6748bf13-e404-46f5-f22a-6427e4568a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она']\n"
          ]
        }
      ],
      "source": [
        "# загружаем нужный список стоп-слов\n",
        "sw = stopwords.words('russian')\n",
        "\n",
        "# смотрим, что внутри\n",
        "print(sw[:15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttFXUp0D5Fv8",
        "outputId": "cb1657a3-55f1-4656-ad74-18e541f2195f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['набоков', 'люблю', 'зеленый', 'серый', 'весь', 'заштрихованный', 'дождем', 'липовое', 'столь', 'густое', 'перенести', 'уйдем', 'уйдем', 'сад', 'оставим']\n"
          ]
        }
      ],
      "source": [
        "# токенизируем текст, приводим к нижнему регистру и оставляем только последовательности из букв,\n",
        "# т.е. все токены, где были знаки препинания и числа, исчезнут\n",
        "words = [w.lower() for w in word_tokenize(text, language='russian') if w.isalpha()]\n",
        "\n",
        "# какие слова исчезли?\n",
        "filtered = [w for w in words if w not in sw]\n",
        "print(filtered[:15])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPJlPxvd5Fv9"
      },
      "source": [
        "И наконец-то стемминг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbJ9w-SY5Fv9"
      },
      "outputs": [],
      "source": [
        "# умеет работать не только с английским текстом\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "snowball = SnowballStemmer(\"russian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR1o9YG45Fv9",
        "outputId": "042036d0-1fe8-4f77-cf0a-e8ca35e7ae9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уйдем: уйд\n",
            "безумный: безумн\n",
            "весь: ве\n",
            "густое: густ\n",
            "дождем: дожд\n",
            "дождь: дожд\n",
            "домой: дом\n",
            "есть: ест\n",
            "еще: ещ\n",
            "заштрихованный: заштрихова\n",
            "зеленый: зелен\n",
            "и: и\n",
            "кипящий: кипя\n",
            "липкий: липк\n",
            "липовое: липов\n",
            "люблю: любл\n",
            "между: межд\n",
            "мой: мо\n",
            "на: на\n",
            "не: не\n"
          ]
        }
      ],
      "source": [
        "ruswords = set(word_tokenize(text, language='russian'))\n",
        "\n",
        "for w in sorted(ruswords)[10:30]:\n",
        "    print(\"%s: %s\" % (w, snowball.stem(w)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDaPcOCd5Fv9"
      },
      "source": [
        "По-моему, качество $-$ просто дно.\n",
        "\n",
        "А в лемматизации тут нет русского, но в целом good to know."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up81IWsW5Fv-",
        "outputId": "0d81b986-88af-4510-b3a5-f5dd3fab85ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "wnl = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8VfqsUOK5Fv-",
        "outputId": "a3442e25-7818-48b7-882c-655f9fdd8a00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'run'"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wnl.lemmatize('running', pos='v')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Саммари\n",
        "\n",
        "**Достоинства NLTK**:\n",
        "* хорош для токенизации и разделении на предложения (даже для русского)\n",
        "* справляется с лемматизацией и стемминогом английского\n",
        "* большая библиотека с разным функционалом\n",
        "\n",
        "**Недостатки NLTK**:\n",
        "* в основном, разработана для английского\n",
        "* нет лемматизации на русском\n",
        "* очень некачественный стемминг на русском\n"
      ],
      "metadata": {
        "id": "p9TV7Kdhzz1f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZEiNG9m5Fv5"
      },
      "source": [
        "### SpaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Документация**](https://spacy.io/)\n",
        "\n",
        "Мультиязыковая модель. Если кратко, то SpaCy может примерно всё то же самое, что и NLTK и аналоги (токенизация, лемматизация, POS-тэггинг, построение деревьев заввисимостей и NER), но быстрее и точнее (как минимум, для английского).\n",
        "\n",
        "В целом, сейчас скорее самая популярная для разных задач.\n",
        "\n",
        "Подробнее можно почитать статьи на Хабре:\n",
        "* [покороче](https://habr.com/ru/articles/504680/), но 20-го года, поэтому инфа, например, про отсутствие официальных моделей русского языка устарела;\n",
        "* [подлиннее](https://habr.com/ru/articles/531940/).\n",
        "\n",
        "Можно даже пройти [курс](https://course.spacy.io/en/) от создателей."
      ],
      "metadata": {
        "id": "j5ak8aGCuhUK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3MUtPtX5Fv6"
      },
      "outputs": [],
      "source": [
        "# !pip install typing_extensions==4.7.1 --upgrade --q\n",
        "# !python -m spacy download ru_core_news_sm --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LayEDWReJPyR"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.ru.examples import sentences\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WdH1g-25Fv6",
        "outputId": "b5e54932-9507-4fda-a245-678a84a7e2ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple рассматривает возможность покупки стартапа из Соединённого Королевства за $1 млрд Беспилотные автомобили перекладывают страховую ответственность на производителя\n",
            "Apple PROPN nsubj\n",
            "рассматривает VERB ROOT\n",
            "возможность NOUN obj\n",
            "покупки NOUN nmod\n",
            "стартапа NOUN nmod\n",
            "из ADP case\n",
            "Соединённого ADJ amod\n",
            "Королевства PROPN nmod\n",
            "за ADP case\n",
            "$ NOUN nmod\n",
            "1 NUM nummod\n",
            "млрд NOUN nmod\n",
            "Беспилотные ADJ amod\n",
            "автомобили NOUN nsubj\n",
            "перекладывают VERB conj\n",
            "страховую ADJ amod\n",
            "ответственность NOUN obj\n",
            "на ADP case\n",
            "производителя NOUN obl\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\" \".join(sentences[:2]))\n",
        "print(doc.text)\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emc3LD1Z5Fv-"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Текст $-$ первая глава произведения \"Дар\" Набокова. Файл `nabokov.txt` у нас в [репозитории](https://raw.githubusercontent.com/hse-ling-python/seminars/refs/heads/master/morphology/input_files/nabokov.txt).\n",
        "\n",
        "1. Первое задание $-$ это небольшой эксперимент. Возьмите пять любых абзацев из текста и распарсите их двумя способами.\n",
        "    1. просто через pymystem (`.analyze`) и\n",
        "    2. через pymystem, предварительно почистив текст от пунктуации (тоже `.analyze`).<br>Замерить, что из этого быстрее с помощью line magic ``%time some_python_expression_here``\n",
        "2. Токенизируйте весь текст с помощью nltk.\n",
        "3. Почистите его от знаков препинания (тут пригодится список из первого задания), стоп-слов (с помощью nltk) и слов не на кириллице. Сделайте регистр `lower` у всх слов.\n",
        "4. Лемматизируйте с помощью pymorphy (`.normal_form`)\n",
        "5. Cоставьте частотный список слов. Выведите 20 самых частотных слов вообще.\n",
        "6. Найдите 20 самых частотных существительных.\n",
        "7. В тексте (списку слов), полчившемся после пункта 3 (токенизированному и почищенному), поищите биграммы. Для этого нужно будет посмотреть nltk документацию про `nltk.bigrams()`. Выведите 10 самых частотных биграммов.\n",
        "\n",
        "Напоминание:\n",
        "\n",
        "**N-граммы** $-$ это сочетания из N элементов (слов, символов), идущих друг за другом. Одиночные элементы называются униграммами, сочетания из двух элементов $-$ биграммами, из трёх $-$ триграммами, а дальше все пишется цифрами: 4-граммы, 5-граммы и т.д."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}