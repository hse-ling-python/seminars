# ДЗ-7: классификация

**Мягкий дедлайн** 25 февраля 23:59.
**Жёсткий дедлайн** 1 марта 23:59.
## Ссылки для сдачи:

HW7-241 https://classroom.github.com/a/BAPY-Zh6

HW7-242 https://classroom.github.com/a/luUSOv5p

HW7-243 https://classroom.github.com/a/636cp-Yf

## Задача

Нужно решить задачу классификации отзывов о фильмах на положительные и отрицательные. Цель - получить как можно более высокое качество ответов.

Можно работать в команде (максимально 3 человека, можно из разных групп).

## Данные

Данные - это перемешанный [публичный датасет](https://aclanthology.org/P11-1015/).

```train.csv``` - [тренировочные данные](https://github.com/hse-ling-python/seminars/blob/master/homework22-23/hw7/train.csv.zip) с ответами

```test.csv``` - [тестовые данные](https://github.com/hse-ling-python/seminars/blob/master/homework22-23/hw7/test.csv.zip), ответы на которые вы должны предсказать и загрузить в репозиторий

```sample_submission.csv``` - [пример](https://github.com/hse-ling-python/seminars/blob/master/homework22-23/hw7/sample_submission.csv) того, как должен выглядеть файл ответов, его можно получить так:

```
result = test[["id"]].copy()
result["answer"] = y_pred   # ваши предсказания
result.to_csv("result.csv", index=False)
```

Столбцы:

+ ```id``` - ID текста
+ ```text``` - текст отзыва
+ ```answer``` - отметка отзыва (0 - негативный, 1 - позитивный)


## Правила

Можно:

    + пробовать разные модели
    + использовать морфологический анализатор, синтаксический и любые другие (для создания признаков и векторизации)

Нельзя:

    + использовать готовые библиотеки или словари для анализа тональности
    + списывать
    + доставать правильные ответы из оригинального датасета

Использование запрещенных данных / инструментов ведет к 0 за задание.

## Работа

Вы тестируете модель на части данных, итоговая оценка модели может измениться, когда проверится на всех данных. 
Мы хотим сделать качественную модель с высокой обобщающей способностью, а не выучить данные.

Необходимо:
1. Построить модели, оформить тетрадку, написать комментарии
2. Сохранить результаты в .csv файл, см. выше
3. Выбрать лучшие модели из протестированных по логике или по качеству, в конце тетрадки прописать, какая модель справилась лучше всего, привести соответствующие метрики
4. Загрузить тетрадку с кодом и комментариями, а также .csv файл с результатами (см. выше, как он создается) в репозиторий, **проверить, что в начале тетрадки указаны имена всех участников команды, даже если вы работали индивидуально**
5. Если вы работали в команде (2-3 человека), то загружает в репозиторий кто-то один, указывает имена всех участников в readme и в тетрадке.
6. Если у проверяющих возникнут вопросы, они могут задать их индивидально любому члену команды, чтобы проверить понимание студентом кода и хода работы.

## Оценка

Базовые решения-ориентиры:

+ на 4 балла качество модели -- примерно 0.7, решение хуже самого простого, но какие-то ответы лучше случайных
+ на 6 баллов качество модели -- примерно 0.87, самое простое решение: просто tf-idf на 1000 признаков + лог регрессия

Если не нарушены правила и вы создаете модель лучше этого, то точно получаете оценку не ниже. Оценки выше зависят от качества модели + комментариев, хода тестирования (будет составлен рейтинг, лучшие работы могут претендовать на 10, занявшие второе место -- на 9 и т.д.). 

Решение должно воспроизводиться! Для воспроизводимости указывайте random state.



