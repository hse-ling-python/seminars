{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Краулеры\n",
    "\n",
    "**План**\n",
    "\n",
    "1. Что такое краулеры?\n",
    "2. Как написать простой краулер?\n",
    "3. Блокировки и способы их обхода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такое краулеры?\n",
    "\n",
    "Краулеры - это боты/программы, которые \"ползают\" по страницам сайта и собирают информацию. Все чаще использование таких программ запрещается правилами пользования сайтами, поэтому это формально нехорошо. Но так продолжают делать и это надо уметь. Запрещают по 2 основным причинам: не хотят делиться данными и боятся, что вы уроните сервер (если сайт маленький и сервер не очень, то это довольно легко). Поэтому нужно собирать данные аккуратно, чтобы вас а) не заблокировали по IP и б) вы не навредили серверу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как написать простой краулер?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо отдельных запросов лучше создать сессию, которая позволит хранить информацию между запросами и поддерживать то же соединение и не создавать каждый раз все заново, что влияет на производительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать запрос, просто вместо requests.get мы пишет session.get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = session.get('https://ru.wikipedia.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Может найти значения нашего IP-адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'82.204.189.106'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.headers['X-Client-IP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли нас отследить по IP? С определенной точностью, можно узнать округ или компанию, к которой привязан любой IP. Пример сервиса, который позволяет это сделать [здесь](https://whatismyipaddress.com/ip-lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть на headers запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accept-ch': '',\n",
      " 'accept-ranges': 'bytes',\n",
      " 'age': '635',\n",
      " 'cache-control': 'private, s-maxage=0, max-age=0, must-revalidate',\n",
      " 'content-encoding': 'gzip',\n",
      " 'content-language': 'ru',\n",
      " 'content-length': '28907',\n",
      " 'content-type': 'text/html; charset=UTF-8',\n",
      " 'date': 'Tue, 07 Nov 2023 11:01:09 GMT',\n",
      " 'last-modified': 'Tue, 07 Nov 2023 11:01:06 GMT',\n",
      " 'nel': '{ \"report_to\": \"wm_nel\", \"max_age\": 604800, \"failure_fraction\": 0.05, '\n",
      "        '\"success_fraction\": 0.0}',\n",
      " 'report-to': '{ \"group\": \"wm_nel\", \"max_age\": 604800, \"endpoints\": [{ \"url\": '\n",
      "              '\"https://intake-logging.wikimedia.org/v1/events?stream=w3c.reportingapi.network_error&schema_uri=/w3c/reportingapi/network_error/1.0.0\" '\n",
      "              '}] }',\n",
      " 'server': 'mw1442.eqiad.wmnet',\n",
      " 'server-timing': 'cache;desc=\"hit-front\", host;desc=\"cp3068\"',\n",
      " 'set-cookie': 'WMF-DP=ce4;Path=/;HttpOnly;secure;Expires=Tue, 07 Nov 2023 '\n",
      "               '00:00:00 GMT, '\n",
      "               'NetworkProbeLimit=0.001;Path=/;Secure;Max-Age=3600',\n",
      " 'strict-transport-security': 'max-age=106384710; includeSubDomains; preload',\n",
      " 'vary': 'Accept-Encoding,Cookie',\n",
      " 'x-cache': 'cp3068 miss, cp3068 hit/333',\n",
      " 'x-cache-status': 'hit-front',\n",
      " 'x-client-ip': '82.204.189.106',\n",
      " 'x-content-type-options': 'nosniff'}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict(response.headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратегии сбора данных\n",
    "\n",
    "\n",
    "По сути краулеры выполняют сбор страниц (их html) как мы это делали на прошлом занятии, но делают они это циклами (или циклами циклов). Можно выделить разные стратегии сбора данных:\n",
    "    \n",
    "**По типу навигации**\n",
    "\n",
    "1. Все страницы со ссылками имеют удобные номера (\"https://ficbook.net/fanfiction/no_fandom/originals?p=2\"), обычно просто p=(число) или page=(число). В этом случае вам нужно просто подставлять цифры подробнее про параметры передаваемые в ссылке можно посмотреть [здесь](https://en.wikipedia.org/wiki/Query_string)\n",
    "2. Страницы называются как-то не структурированно (например, по названиям блоков). Тут нужно собирать ссылки на эти страницы и потом по ним ходить и собирать конечные странички.\n",
    "3. Все расположено на одной страничке и догружается с использованием [WebSocket](https://en.wikipedia.org/wiki/WebSocket) или других технологий, при адрес в адресной строке никак не изменяется, данные могут догружаться на сайт автоматически по мере скролла страницы\n",
    "\n",
    "**По скорости обновления**\n",
    "\n",
    "1. Если сайт довольно статичный по контенту (медленно появляются и удаляются материалы), то можно сначал собрать ссылки, а потом по ним ходить\n",
    "2. Если сайт очень динамичный по контенту (например, объявления на крупном сайте), вам нужно при получении страничкии ссылок сразу их обходить, а потом переходить к следующей, потому что ко времени получения исчерпывающего списка ссылок по сайту многие будут уже удалены или недоступны\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блокировки и способы их обхода\n",
    "\n",
    "Для того, чтобы предотвратить автоматический сбор информации с некого сайта, применяются различные инструменты, которые определяют роботов и блокируют запросы с адресов, которые были классифицированы как роботы. Чтобы не заблокировали домашний/учебный ip, лучше сразу задуматься об этих мерах и предотвратить возможные проблемы. Кстати, Википедия не блокирует и можно спокойно скачивать без каких-либо проблем.\n",
    "\n",
    "Чтобы их обойти, можно попробовать несколько инструментов:\n",
    "1. time.sleep(x) - задержка между запросами, чтобы слишком большая скорость запросов не показалась подозрительной или ваши запросы не уронили сервер небольшого ресурса (например, региональной газеты)\n",
    "2. time.sleep(случайный промежуток времени) - это более хитрая версия, когда время задержки - это случайное число из некоторого отрезка (модуль random)\n",
    "3. изобразить браузер - при запросе отправляется информация о том, из какого приложения пришел запрос (например, Googlr Chrome), запросы сделанные из браузера больше похожи на человеческие, для этого нужно задать user-agent в параметрах (а его выбирать случайно с помощью fake_useragent)\n",
    "4. использовать прокси - существуют ресурсы с бесплатными списками открытых прокси, через которые можно пропускать ваш запрос и сервер будет думать, что запросы приходят из разных мест (anonymous и elite классы прокси) или использовать анонимизированные сети к примеру сеть [Tor](https://en.wikipedia.org/wiki/Tor_(network)) и аналоги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пауза между запросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:11:46.059835\n",
      "2023-11-07 14:11:47.180260\n",
      "2023-11-07 14:11:48.321168\n",
      "2023-11-07 14:11:49.446220\n",
      "2023-11-07 14:11:50.587486\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    response = session.get('https://ru.wikipedia.org')\n",
    "    print(datetime.now())\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Притвориться нормальным браузером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно настроить так, чтобы не проверять безопасность соединения, что иногда вызывает ошибки. Но это можно делать с сайтмаи, которым вы доверяете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'}\n"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': ua.random}\n",
    "print(headers)\n",
    "response = session.get('https://ru.wikipedia.org', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пауза между запросами (случайное время)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random.uniform позволяет получить случайное число из отрезка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.462199182905924"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:11:52.070324\n",
      "2023-11-07 14:11:55.550406\n",
      "2023-11-07 14:11:57.081575\n",
      "2023-11-07 14:11:59.064115\n",
      "2023-11-07 14:12:04.096389\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    response = session.get('https://ru.wikipedia.org')\n",
    "    print(datetime.now())\n",
    "    time.sleep(random.uniform(1.1, 5.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение через прокси\n",
    "\n",
    "Прокси-сервер — это дополнительное звено между вами и интернетом, через него пойдет подключение и сайт не будет знать, что это вы посылаете запрос.\n",
    "\n",
    "Адреса прокси можно взять со специальных сайтов, например, [https://hideip.me/ru/proxy/httplist](https://hideip.me/ru/proxy/httplist). И потом проверить, что они рабочие, прежде чем использовать [https://checkerproxy.net/](https://checkerproxy.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.204.189.106\n"
     ]
    }
   ],
   "source": [
    "known_proxy_ip = '176.213.141.107:8080'\n",
    "#proxy = {'http': known_proxy_ip, 'https': known_proxy_ip}\n",
    "proxy = {\"https://\": \"https://176.213.141.107:8080\"}\n",
    "http_proxy  = \"http://10.10.1.10:3128\"\n",
    "https_proxy = \"https://10.10.1.11:1080\"\n",
    "ftp_proxy   = \"ftp://10.10.1.10:3128\"\n",
    "\n",
    "proxies = { \n",
    "              \"http\"  : http_proxy, \n",
    "              \"https\" : https_proxy, \n",
    "              \"ftp\"   : ftp_proxy\n",
    "            }\n",
    "response = session.get('http://ru.wikipedia.org', proxies=proxy)\n",
    "print(response.headers['X-Client-IP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры\n",
    "\n",
    "### Пример 1\n",
    "\n",
    "Давайте обкачаем немного новостей с сайта вышки.\n",
    "\n",
    "1. Страницы имеют вид \"https://www.hse.ru/news/page1.html\", поэтому можно просто идти циклом.\n",
    "2. Достанем дату публикации, заголовок, краткое описание (из станицы со списком новостей), текст полной статьи и метки (из самой страницы новости)\n",
    "3. Сохраним в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, tags, pub_year, pub_month, pub_dat, title,short_text, full_text,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отработаем процесс на одной странице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 1. Найти страницы**\n",
    "\n",
    "Посмотрим, как устроены новости и скачаем одну страницу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 1\n",
    "url = f'https://www.hse.ru/news/page{page_number}.html'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распарсим с помощью BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем отдельные посты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = soup.find_all('div', {'class': 'post'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем заголовок-ссылку и запомним текст заголовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"link link_dark2 no-visited\" href=\"/news/edu/871214248.html\">ВШЭ, «Яндекс» и «Сириус» запустили бесплатный курс по ИИ для школьников</a>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_obj = news[0].find('a')\n",
    "title_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ВШЭ, «Яндекс» и «Сириус» запустили бесплатный курс по ИИ для школьников'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = title_obj.text\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достанем свойства этой ссылки (куда ведет, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'href': '/news/edu/871214248.html',\n",
       " 'class': ['link', 'link_dark2', 'no-visited']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs = title_obj.attrs\n",
    "attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достанем саму ссылку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/news/edu/871214248.html'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href = title_obj.attrs['href']\n",
    "href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достанем текст новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Факультет компьютерных наук НИУ ВШЭ, «Яндекс» и «Сириус.Курсы» запустили бесплатный курс по искусственному интеллекту для школьников\\xa0«Глубокое обучение». Старшеклассники узнают, как работают и обучаются нейросети, и познакомятся с востребованными IT-профессиями. Записаться на осенний поток можно до 15 ноября.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_text = news[0].find('div', {'class': 'post__text'}).text\n",
    "short_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достанем день, месяц, год публикации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_day = news[0].find('div', {'class': 'post-meta__day'}).text\n",
    "pub_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ноя'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_month = news[0].find('div', {'class': 'post-meta__month'}).text\n",
    "pub_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_year = news[0].find('div', {'class': 'post-meta__year'}).text\n",
    "pub_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 2. Научиться парсить страничку самой новости**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем ссылку на полную новость и соединим с адерсом сайта (т.к. ссылка относительная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.hse.ru/news/edu/871214248.html'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_one = 'http://www.hse.ru' + href\n",
    "url_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем ее и распарсим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = session.get(url_one, headers={'User-Agent': ua.random})\n",
    "page = req.text\n",
    "\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним текст, распечатаем кусочек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ВШЭ, «Яндекс» и «Сириус» запустили бесплатный курс по ИИ для школьниковФото: образовательный центр «Сириус»Факультет компьютерных наук НИУ ВШЭ, «Яндекс» и «Сириус.Курсы» запустили бесплатный курс по и'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = soup.find('div', {'class': 'post__content'}).text\n",
    "full_text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем теги, которые присвоены статье"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['новое в ВШЭ',\n",
       " 'приглашение к участию',\n",
       " 'довузовская подготовка',\n",
       " 'искусственный интеллект']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = soup.find('div', {'class': 'articleMeta'})\n",
    "\n",
    "tags = meta.find_all('a', {'class': 'tag'})\n",
    "tags = [t.text for t in tags]\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 3. Оформляем нормально в функции**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем словарь соответствий имени месяца и его номера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\n",
    "    value: key + 1\n",
    "    for key, value in enumerate(\n",
    "        ['янв', 'фев', 'мар', 'апр', 'мая', 'июн', 'июл', 'авг', 'сен', 'окт', 'ноя', 'дек']\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим информацию из страницы со списком новостей (блок одной новости)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news_page_block(one_block):\n",
    "    block = {}\n",
    "    a = one_block.find('a')\n",
    "    block['title'] = a.text\n",
    "    block['href'] = a.attrs['href']\n",
    "    block['short_text'] = one_block.find('div', {'class': 'post__text'}).text\n",
    "    block['pub_day'] = int(one_block.find('div', {'class': 'post-meta__day'}).text)\n",
    "    block['pub_month'] = months[one_block.find('div', {'class': 'post-meta__month'}).text]\n",
    "    block['pub_year'] = int(one_block.find('div', {'class': 'post-meta__year'}).text)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим отдельную страницу новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_article(block):\n",
    "    url_one = 'http://www.hse.ru' + block['href']\n",
    "    req = session.get(url_one, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    block['full_text'] = soup.find('div', {'class': 'post__content'}).text\n",
    "    meta = soup.find('div', {'class': 'articleMeta'})\n",
    "    tags = meta.find_all('a', {'class': 'tag'})\n",
    "    block['tags'] = [t.text for t in tags]     \n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регулярное выражение для того, чтобы достать ID новости и не повторяться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_hse_id = re.compile('/([0-9]*?).html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработать N-ую страницу новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_page(page_number, seen_news):\n",
    "    # скачиваем\n",
    "    url = f'https://www.hse.ru/news/page{page_number}.html'\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    # находим новости\n",
    "    news = soup.find_all('div', {'class': 'post'})\n",
    "    \n",
    "    # идем по новостям и обрабатываем их\n",
    "    blocks = []\n",
    "    for n in news:\n",
    "        try:\n",
    "            blocks.append(parse_news_page_block(n))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # идем по отдельным статьям и достаем информацию\n",
    "    result = []\n",
    "    for b in blocks:\n",
    "        if b['href'].startswith('/'):\n",
    "            idx = regex_hse_id.findall(b['href'])[0]\n",
    "            if idx not in seen_news:\n",
    "                try:\n",
    "                    res = parse_one_article(b)\n",
    "                    res['hse_id'] = idx\n",
    "                    result.append(res)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            else:\n",
    "                print('Seen', b['href'])\n",
    "    \n",
    "    # возвращаем найденную информацию\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 4. Пишем в базу**\n",
    "\n",
    "Надо завести словарь для тегов (сначала читаем из базы, а потом дозаписываем), множество виденных статей (чтобы при перезаупске не дублировать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, куда передаем количество страниц и она выполняет все нужные действия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>href</th>\n",
       "      <th>short_text</th>\n",
       "      <th>pub_day</th>\n",
       "      <th>pub_month</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tags</th>\n",
       "      <th>hse_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Успеть до 8 ноября: регистрацию на «Высшую про...</td>\n",
       "      <td>/news/admission/870148337.html</td>\n",
       "      <td>Завершается регистрация на Всероссийскую олимп...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>Успеть до 8 ноября: регистрацию на «Высшую про...</td>\n",
       "      <td>[бакалавриат, олимпиада «Высшая проба», олимпи...</td>\n",
       "      <td>870148337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>«Было очень приятно увидеть, какие люди здесь ...</td>\n",
       "      <td>/news/admission/870127221.html</td>\n",
       "      <td>В конце октября Высшую школу экономики посетил...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>«Было очень приятно увидеть, какие люди здесь ...</td>\n",
       "      <td>[довузовская подготовка]</td>\n",
       "      <td>870127221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Эксперты НИУ ВШЭ рассказали о перспективах кар...</td>\n",
       "      <td>/news/expertise/870132139.html</td>\n",
       "      <td>Международный центр конкурентного права и поли...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>Эксперты НИУ ВШЭ рассказали о перспективах кар...</td>\n",
       "      <td>[репортаж о событии, БРИКС, Казахстан, карбоно...</td>\n",
       "      <td>870132139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Россия и Средиземноморье: вызовы и перспективы...</td>\n",
       "      <td>/news/expertise/870116125.html</td>\n",
       "      <td>Взаимосвязь задач по поддержанию мира, сохране...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>Россия и Средиземноморье: вызовы и перспективы...</td>\n",
       "      <td>[дискуссии, репортаж о событии, международное ...</td>\n",
       "      <td>870116125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Отборочный этап чемпионата сочинений «Своими с...</td>\n",
       "      <td>/news/edu/869967318.html</td>\n",
       "      <td>С 27 по 30 октября состоялся отборочный этап В...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>Отборочный этап чемпионата сочинений «Своими с...</td>\n",
       "      <td>[довузовская подготовка, олимпиады НИУ ВШЭ, св...</td>\n",
       "      <td>869967318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Дорога к звездам: ВШЭ продолжает кинопоказы вм...</td>\n",
       "      <td>/news/community/869891477.html</td>\n",
       "      <td>В конце октября состоялся очередной кинопоказ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>Дорога к звездам: ВШЭ продолжает кинопоказы вм...</td>\n",
       "      <td>[лектории, кино]</td>\n",
       "      <td>869891477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Опубликованы правила приема в НИУ ВШЭ в 2024 году</td>\n",
       "      <td>/news/admission/869900080.html</td>\n",
       "      <td>На сайте Приемной комиссии появилась информаци...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>Опубликованы правила приема в НИУ ВШЭ в 2024 г...</td>\n",
       "      <td>[бакалавриат, магистратура, поступающим, прием...</td>\n",
       "      <td>869900080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>«Площадка для коммуникации и пополнения банка ...</td>\n",
       "      <td>/news/edu/869869183.html</td>\n",
       "      <td>В конце октября в Москве прошел образовательны...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>«Площадка для коммуникации и пополнения банка ...</td>\n",
       "      <td>[репортаж о событии, лицей НИУ ВШЭ]</td>\n",
       "      <td>869869183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>«Наследие + Дизайн»: музейный форум прошел в Н...</td>\n",
       "      <td>/news/expertise/869847802.html</td>\n",
       "      <td>В конце октября на площадке CREATIVE HUB проше...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>«Наследие + Дизайн»: музейный форум прошел в Н...</td>\n",
       "      <td>[идеи и опыт, дискуссии, репортаж о событии]</td>\n",
       "      <td>869847802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Успеть до 8 ноября: регистрацию на «Высшую про...   \n",
       "1  «Было очень приятно увидеть, какие люди здесь ...   \n",
       "2  Эксперты НИУ ВШЭ рассказали о перспективах кар...   \n",
       "3  Россия и Средиземноморье: вызовы и перспективы...   \n",
       "4  Отборочный этап чемпионата сочинений «Своими с...   \n",
       "5  Дорога к звездам: ВШЭ продолжает кинопоказы вм...   \n",
       "6  Опубликованы правила приема в НИУ ВШЭ в 2024 году   \n",
       "7  «Площадка для коммуникации и пополнения банка ...   \n",
       "8  «Наследие + Дизайн»: музейный форум прошел в Н...   \n",
       "\n",
       "                             href  \\\n",
       "0  /news/admission/870148337.html   \n",
       "1  /news/admission/870127221.html   \n",
       "2  /news/expertise/870132139.html   \n",
       "3  /news/expertise/870116125.html   \n",
       "4        /news/edu/869967318.html   \n",
       "5  /news/community/869891477.html   \n",
       "6  /news/admission/869900080.html   \n",
       "7        /news/edu/869869183.html   \n",
       "8  /news/expertise/869847802.html   \n",
       "\n",
       "                                          short_text  pub_day  pub_month  \\\n",
       "0  Завершается регистрация на Всероссийскую олимп...        2         11   \n",
       "1  В конце октября Высшую школу экономики посетил...        2         11   \n",
       "2  Международный центр конкурентного права и поли...        2         11   \n",
       "3  Взаимосвязь задач по поддержанию мира, сохране...        2         11   \n",
       "4  С 27 по 30 октября состоялся отборочный этап В...        1         11   \n",
       "5  В конце октября состоялся очередной кинопоказ ...        1         11   \n",
       "6  На сайте Приемной комиссии появилась информаци...        1         11   \n",
       "7  В конце октября в Москве прошел образовательны...        1         11   \n",
       "8  В конце октября на площадке CREATIVE HUB проше...        1         11   \n",
       "\n",
       "   pub_year                                          full_text  \\\n",
       "0      2023  Успеть до 8 ноября: регистрацию на «Высшую про...   \n",
       "1      2023  «Было очень приятно увидеть, какие люди здесь ...   \n",
       "2      2023  Эксперты НИУ ВШЭ рассказали о перспективах кар...   \n",
       "3      2023  Россия и Средиземноморье: вызовы и перспективы...   \n",
       "4      2023  Отборочный этап чемпионата сочинений «Своими с...   \n",
       "5      2023  Дорога к звездам: ВШЭ продолжает кинопоказы вм...   \n",
       "6      2023  Опубликованы правила приема в НИУ ВШЭ в 2024 г...   \n",
       "7      2023  «Площадка для коммуникации и пополнения банка ...   \n",
       "8      2023  «Наследие + Дизайн»: музейный форум прошел в Н...   \n",
       "\n",
       "                                                tags     hse_id  \n",
       "0  [бакалавриат, олимпиада «Высшая проба», олимпи...  870148337  \n",
       "1                           [довузовская подготовка]  870127221  \n",
       "2  [репортаж о событии, БРИКС, Казахстан, карбоно...  870132139  \n",
       "3  [дискуссии, репортаж о событии, международное ...  870116125  \n",
       "4  [довузовская подготовка, олимпиады НИУ ВШЭ, св...  869967318  \n",
       "5                                   [лектории, кино]  869891477  \n",
       "6  [бакалавриат, магистратура, поступающим, прием...  869900080  \n",
       "7                [репортаж о событии, лицей НИУ ВШЭ]  869869183  \n",
       "8       [идеи и опыт, дискуссии, репортаж о событии]  869847802  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_nth_page(2, seen_news=set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(n_pages):\n",
    "    blocks = []\n",
    "    for i in tqdm(range(n_pages)):\n",
    "        blocks.extend(get_nth_page(i+1, seen_news=set()))\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем на 20 первых страниц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b342083416d74ff8a714bdab7c3cbd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "blocks = run_all(20)\n",
    "\n",
    "df = pd.DataFrame(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на 10 самых популярных тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [tag for tag_list in df[\"tags\"] for tag in tag_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 \t репортаж о событии\n",
      "25 \t студенты\n",
      "22 \t международное сотрудничество\n",
      "20 \t Программа развития 2030\n",
      "20 \t приглашение к участию\n",
      "19 \t Приоритет 2030\n",
      "18 \t исследования и аналитика\n",
      "16 \t довузовская подготовка\n",
      "16 \t достижения\n",
      "16 \t магистратура\n"
     ]
    }
   ],
   "source": [
    "for title, counts in sorted(Counter(tags).items(), key=lambda x: -x[-1])[:10]:\n",
    "    print(counts,\"\\t\", title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько публикаций по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pub_month\n",
       "8      3\n",
       "9     76\n",
       "10    62\n",
       "11    16\n",
       "Name: hse_id, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"pub_month\")[\"hse_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ce43fa76ab3efd8b793de81ff92f0816c1b946b31e6af34d67351b015f361e9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
