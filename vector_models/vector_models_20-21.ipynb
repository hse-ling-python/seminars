{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторные модели. Word2Vec\n",
    "\n",
    "+ Firth (1957:11):\n",
    "You shall know a word by the company it keeps . . .\n",
    "\n",
    "+ Дистрибутивная гипотеза: значение слова определяется его контекстом — иначе говоря, словами, которые встречаются рядом с этим словом в тексте. \n",
    "\n",
    "+ Область лингвистики, которая занимается вычислением степени семантической близости между словами/текстами и т.п. на основании их распределения (дистрибуции) в больших массивах данных (текстовых корпусах) назвается **дистрибутивной семантикой**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кратко о существующих системах\n",
    "\n",
    "**GloVe**\n",
    "\n",
    "GloVe берет и строит полную матрицу совместной встречаемости и после этого с помощью алгоритомв уменьшения размерности преобразует ее так, чтобы вектора были опредленной длины\n",
    "\n",
    "\n",
    "**Word2Vec**\n",
    "\n",
    "Это уже нейросеть и она на основе корпуса постепенно подбирает коэффициенты (значения в векторах) для каждого слова так, чтобы с помощью них можно было наилучшим образом предсказывать слова по контексту\n",
    "\n",
    "**FastText**\n",
    "\n",
    "Если мы берем конкретные слова, мы не можем ничего сказать о тех, что нам не встретились (например, уже видели вагон и строитель, а вот вагоностроителя у нас не было). Если мы возьмем слова не целиком, а в виде будквенных нграмм, то мы сможем сложить неизвестные слова.\n",
    "\n",
    "**AdaGram**\n",
    "\n",
    "Все предыдущие модели основаны на графических оболочках и не учитывают многозначность и омонимию. Есть только один вектор для слова \"ключ\" и мы ничего с этим не можем сделать. AdaGram исходит из предположения, что у слова есть n вариантов и если они действительно отличаются и достаточно часто встречаются, он умеет их разделить.\n",
    "\n",
    "**BERT и ELMo**\n",
    "\n",
    "Эти модели не просто могут отличить значения слов, о и скорректировать их вектора в зависимости от контекста, например, понять, что в отрывках “чистый ключ в лесной чаще” и “ключ от квартиры” совсем разные “ключи”. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из самых известных моделей для работы с дистрибутивной семантикой является word2vec. Технология основана на нейронной сети, предсказывающей вероятность встретить слово в заданном контексте. Этот инструмент был разработан группой исследователей Google в 2013 году, руководителем проекта был Томаш Миколов (сейчас работает в Facebook). Вот две самые главные статьи:\n",
    "\n",
    "+ [Efficient Estimation of Word Representations inVector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "+ [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n",
    "\n",
    "Полученные таким образом вектора называются распределенными представлениями слов, или **эмбеддингами**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как это обучается?\n",
    "\n",
    "Мы задаём вектор для каждого слова с помощью матрицы $w$ и вектор контекста с помощью матрицы $W$. По сути, word2vec является обобщающим названием для двух архитектур Skip-Gram и Continuous Bag-Of-Words (CBOW).\n",
    "\n",
    "+ **CBOW** предсказывает текущее слово, исходя из окружающего его контекста.\n",
    "\n",
    "+ **Skip-gram**, наоборот, использует текущее слово, чтобы предугадывать окружающие его слова.\n",
    "\n",
    "#### Как это работает?\n",
    "\n",
    "Word2vec принимает большой текстовый корпус в качестве входных данных и сопоставляет каждому слову вектор, выдавая координаты слов на выходе. Сначала он создает словарь, «обучаясь» на входных текстовых данных, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, согласно дистрибутивной гипотезе, имеющие схожий смысл), в векторном представлении будут иметь близкие координаты векторов-слов. Для вычисления близости слов используется косинусное расстояние между их векторами.\n",
    "\n",
    "С помощью дистрибутивных векторных моделей можно строить семантические пропорции (они же аналогии) и решать примеры:\n",
    "\n",
    "+ король: мужчина = королева: женщина $\\Rightarrow$\n",
    "+ король - мужчина + женщина = королева\n",
    "\n",
    "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)\n",
    "\n",
    "Ещё про механику с картинками [тут](https://habr.com/ru/post/446530/)\n",
    "\n",
    "#### Зачем это нужно?\n",
    "\n",
    "+ используется для решения семантических задач\n",
    "+ давайте подумаем, для описания каких семантических классов слов дистрибутивная информация особенно важна?\n",
    "+ несколько интересных статей по дистрибутивной семантике:\n",
    "\n",
    "* [Turney and Pantel 2010](https://jair.org/index.php/jair/article/view/10640)\n",
    "* [Lenci 2018](https://www.annualreviews.org/doi/abs/10.1146/annurev-linguistics-030514-125254?journalCode=linguistics)\n",
    "* [Smith 2019](https://arxiv.org/pdf/1902.06006.pdf)\n",
    "* [Pennington et al. 2014](https://www.aclweb.org/anthology/D14-1162/)\n",
    "* [Faruqui et al. 2015](https://www.aclweb.org/anthology/N15-1184/)\n",
    "\n",
    "+ подаётся на вход нейронным сетям\n",
    "+ используется в Siri, Google Assistant, Alexa, Google Translate...\n",
    "\n",
    "#### Gensim\n",
    "\n",
    "Использовать предобученную модель эмбеддингов или обучить свою можно с помощью библиотеки `gensim`. Вот ее [документация](https://radimrehurek.com/gensim/models/word2vec.html). Вообще-то `gensim` — библиотека для тематического моделирования текстов, но один из компонентов в ней — реализация на python алгоритмов из библиотеки word2vec (которая в оригинале была написана на C++).\n",
    "\n",
    "Если gensim у вас не стоит, то ставим: `pip install gensim`. Можно сделать это прямо из jupyter'а! Чтобы выполнить какую-то команду не в питоне, в командной строке, нужно написать перед ней восклицательный знак.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как обучить свою модель\n",
    "\n",
    "NB! Обратите внимание, что тренировка модели не включает препроцессинг! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели.\n",
    "\n",
    "Поскольку иногда тренировка модели занимает много времени, то можно ещё вести лог событий, чтобы понимать, что на каком этапе происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход модели даем текстовый файл, каждое предложение на отдельной строчке. Вот игрушечный пример с текстом «Бедной Лизы». Он заранее очищен от пунктуации, приведен к нижнему регистру и лемматизирован."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'liza_lem.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель. Основные параметры:\n",
    "\n",
    "+ данные должны быть итерируемым объектом\n",
    "+ size — размер вектора,\n",
    "+ window — размер окна наблюдения,\n",
    "+ min_count — мин. частотность слова в корпусе,\n",
    "+ sg — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n",
    "+ sample — порог для downsampling'a высокочастотных слов,\n",
    "+ workers — количество потоков,\n",
    "+ alpha — learning rate,\n",
    "+ iter — количество итераций,\n",
    "+ max_vocab_size — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение привышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 13:55:35,204 : INFO : collecting all words and their counts\n",
      "2019-10-17 13:55:35,206 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-10-17 13:55:35,209 : INFO : collected 1213 word types from a corpus of 3109 raw words and 392 sentences\n",
      "2019-10-17 13:55:35,210 : INFO : Loading a fresh vocabulary\n",
      "2019-10-17 13:55:35,212 : INFO : effective_min_count=2 retains 478 unique words (39% of original 1213, drops 735)\n",
      "2019-10-17 13:55:35,213 : INFO : effective_min_count=2 leaves 2374 word corpus (76% of original 3109, drops 735)\n",
      "2019-10-17 13:55:35,216 : INFO : deleting the raw counts dictionary of 1213 items\n",
      "2019-10-17 13:55:35,217 : INFO : sample=0.001 downsamples 83 most-common words\n",
      "2019-10-17 13:55:35,218 : INFO : downsampling leaves estimated 1817 word corpus (76.6% of prior 2374)\n",
      "2019-10-17 13:55:35,220 : INFO : estimated required memory for 478 words and 300 dimensions: 1386200 bytes\n",
      "2019-10-17 13:55:35,220 : INFO : resetting layer weights\n",
      "2019-10-17 13:55:35,231 : INFO : training model with 3 workers on 478 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-10-17 13:55:35,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,243 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,244 : INFO : EPOCH - 1 : training on 3109 raw words (1778 effective words) took 0.0s, 258736 effective words/s\n",
      "2019-10-17 13:55:35,251 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,256 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,257 : INFO : EPOCH - 2 : training on 3109 raw words (1828 effective words) took 0.0s, 184452 effective words/s\n",
      "2019-10-17 13:55:35,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,262 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,268 : INFO : EPOCH - 3 : training on 3109 raw words (1794 effective words) took 0.0s, 199715 effective words/s\n",
      "2019-10-17 13:55:35,273 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,277 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,278 : INFO : EPOCH - 4 : training on 3109 raw words (1808 effective words) took 0.0s, 255070 effective words/s\n",
      "2019-10-17 13:55:35,334 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,335 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,339 : INFO : EPOCH - 5 : training on 3109 raw words (1828 effective words) took 0.1s, 31286 effective words/s\n",
      "2019-10-17 13:55:35,340 : INFO : training on a 15545 raw words (9036 effective words) took 0.1s, 83990 effective words/s\n",
      "2019-10-17 13:55:35,340 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 9.63 ms, total: 158 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%time model_liza = gensim.models.Word2Vec(data, size=300, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно нормализовать вектора, тогда модель будет занимать меньше RAM. Однако после этого её нельзя дотренировывать. Здесь используется L2-нормализация: вектора нормализуются так, что если сложить квадраты всех элементов вектора, в сумме получится 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 13:55:45,348 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-10-17 13:55:45,356 : INFO : storing 478x300 projection weights into liza.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_liza.init_sims(replace=True)\n",
    "model_path = \"liza.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_liza.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим, сколько в модели слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478\n"
     ]
    }
   ],
   "source": [
    "print(len(model_liza.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['анюта', 'армия', 'ах', 'барин', 'бедный', 'белый', 'берег', 'березовый', 'беречь', 'бесчисленный', 'благодарить', 'бледный', 'блеснуть', 'блестящий', 'близ', 'бог', 'богатый', 'большой', 'бояться', 'брать', 'бросать', 'бросаться', 'бывать', 'быть', 'важный', 'ввечеру', 'вдова', 'велеть', 'великий', 'великолепный', 'верить', 'верно', 'весело', 'веселый', 'весна', 'вести', 'весь', 'весьма', 'ветвь', 'ветер', 'вечер', 'взглядывать', 'вздох', 'вздыхать', 'взор', 'взять', 'вид', 'видеть', 'видеться', 'видный', 'вместе', 'вода', 'возвращаться', 'воздух', 'война', 'воображать', 'воображение', 'воспоминание', 'восторг', 'восхищаться', 'время', 'все', 'вслед', 'вставать', 'встречаться', 'всякий', 'высокий', 'выть', 'выходить', 'глаз', 'глубокий', 'гнать', 'говорить', 'год', 'голос', 'гора', 'горе', 'горестный', 'горлица', 'город', 'горький', 'господь', 'гром', 'грусть', 'давать', 'давно', 'далее', 'дверь', 'движение', 'двор', 'девушка', 'дело', 'день', 'деньги', 'деревня', 'деревянный', 'десять', 'добро', 'добрый', 'довольно', 'доживать', 'долго', 'должный', 'дом', 'домой', 'дочь', 'древний', 'друг', 'другой', 'дуб', 'думать', 'душа', 'едва', 'ехать', 'жалобный', 'желание', 'желать', 'жениться', 'жених', 'женщина', 'жестокий', 'живой', 'жизнь', 'жить', 'забава', 'заблуждение', 'забывать', 'завтра', 'задумчивость', 'закраснеться', 'закричать', 'заря', 'здешний', 'здравствовать', 'зеленый', 'земля', 'златой', 'знать', 'ибо', 'играть', 'идти', 'имя', 'искать', 'исполняться', 'испугаться', 'история', 'исчезать', 'кабинет', 'казаться', 'какой', 'капля', 'карета', 'карман', 'картина', 'катиться', 'келья', 'клятва', 'колено', 'копейка', 'который', 'красота', 'крест', 'крестьянин', 'крестьянка', 'кровь', 'кроме', 'кто', 'купить', 'ландыш', 'ласка', 'ласковый', 'левый', 'лес', 'лететь', 'летний', 'лето', 'лиза', 'лизин', 'лизина', 'лицо', 'лишний', 'лодка', 'ложиться', 'луг', 'луч', 'любезный', 'любить', 'любовь', 'лютый', 'матушка', 'мать', 'место', 'месяц', 'мечта', 'милый', 'мимо', 'минута', 'многочисленный', 'могила', 'мой', 'молить', 'молиться', 'молния', 'молодой', 'молодость', 'молчать', 'монастырь', 'море', 'москва', 'москва-река', 'мочь', 'мрак', 'мрачный', 'муж', 'мы', 'мысль', 'наглядеться', 'надеяться', 'надлежать', 'надобно', 'называть', 'наступать', 'натура', 'находить', 'наш', 'небесный', 'небо', 'невинность', 'невинный', 'неделя', 'нежели', 'нежный', 'незнакомец', 'некоторый', 'непорочность', 'неприятель', 'несколько', 'никакой', 'никто', 'новый', 'ночь', 'обижать', 'облако', 'обманывать', 'обморок', 'образ', 'обращаться', 'обстоятельство', 'объятие', 'огонь', 'один', 'однако', 'окно', 'окрестности', 'он', 'она', 'они', 'оно', 'опираться', 'описывать', 'опустеть', 'освещать', 'оставаться', 'оставлять', 'останавливать', 'останавливаться', 'отвечать', 'отдавать', 'отец', 'отечество', 'отменно', 'отрада', 'очень', 'падать', 'память', 'пастух', 'первый', 'перемениться', 'переставать', 'песня', 'петь', 'печальный', 'писать', 'питать', 'плакать', 'побежать', 'побледнеть', 'погибать', 'подавать', 'подгорюниваться', 'подле', 'подозревать', 'подымать', 'поехать', 'пойти', 'показываться', 'поклониться', 'покойный', 'покрывать', 'покрываться', 'покупать', 'полагать', 'поле', 'помнить', 'поселянин', 'последний', 'постой', 'потуплять', 'поцеловать', 'поцелуй', 'правый', 'представляться', 'прежде', 'преклонять', 'прекрасный', 'прелестный', 'приводить', 'прижимать', 'принадлежать', 'принуждать', 'природа', 'приходить', 'приятно', 'приятный', 'провожать', 'продавать', 'проливать', 'простой', 'просыпаться', 'проходить', 'проч', 'прощать', 'прощаться', 'пруд', 'птичка', 'пылать', 'пять', 'работа', 'работать', 'радость', 'рассказывать', 'расставаться', 'рвать', 'ребенок', 'река', 'решаться', 'робкий', 'роза', 'розовый', 'роман', 'российский', 'роща', 'рубль', 'рука', 'сам', 'самый', 'свет', 'светиться', 'светлый', 'свидание', 'свирель', 'свободно', 'свое', 'свой', 'свойство', 'сделать', 'сделаться', 'сей', 'сердечный', 'сердце', 'сидеть', 'сие', 'сиять', 'сказать', 'сказывать', 'сквозь', 'скорбь', 'скоро', 'скрываться', 'слабый', 'слеза', 'слезать', 'слово', 'случаться', 'слушать', 'слышать', 'смерть', 'сметь', 'смотреть', 'собственный', 'соглашаться', 'солнце', 'спасать', 'спокойно', 'спокойствие', 'спрашивать', 'стадо', 'становиться', 'стараться', 'старуха', 'старушка', 'старый', 'статься', 'стена', 'сто', 'столь', 'стон', 'стонать', 'сторона', 'стоять', 'страшно', 'страшный', 'судьба', 'схватывать', 'счастие', 'счастливый', 'сын', 'таить', 'такой', 'твой', 'темный', 'тения', 'тихий', 'тихонько', 'томный', 'тот', 'трава', 'трепетать', 'трогать', 'ты', 'убивать', 'уверять', 'увидеть', 'увидеться', 'удерживать', 'удивляться', 'удовольствие', 'узнавать', 'улица', 'улыбка', 'уметь', 'умирать', 'унылый', 'упасть', 'услышать', 'утешение', 'утро', 'хижина', 'хлеб', 'ходить', 'холм', 'хороший', 'хотеть', 'хотеться', 'хотя', 'худо', 'худой', 'царь', 'цветок', 'целовать', 'час', 'часто', 'человек', 'чистый', 'читатель', 'чувствительный', 'чувство', 'чувствовать', 'чулок', 'шестой', 'шум', 'шуметь', 'щадить', 'щека', 'эраст', 'эрастов', 'это', 'я']\n"
     ]
    }
   ],
   "source": [
    "print(sorted([w for w in model_liza.wv.vocab]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И чему же мы ее научили? Попробуем оценить модель вручную, порешав примеры. Несколько дано ниже, попробуйте придумать свои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('слеза', 0.200484037399292)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.most_similar(positive=[\"смерть\", \"любовь\"], negative=[\"печальный\"], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('слеза', 0.2169419825077057),\n",
       " ('жизнь', 0.18847499787807465),\n",
       " ('сей', 0.1782345473766327)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.most_similar(\"любовь\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14720827"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.similarity(\"лиза\", \"эраст\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'скорбь'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.doesnt_match(\"скорбь грусть слеза улыбка\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['свой',\n",
       " 'сей',\n",
       " 'сердце',\n",
       " 'мой',\n",
       " 'день',\n",
       " 'говорить',\n",
       " 'часто',\n",
       " 'жить',\n",
       " 'слеза',\n",
       " 'цветок',\n",
       " 'время',\n",
       " 'добрый',\n",
       " 'взять',\n",
       " 'чистый',\n",
       " 'любовь',\n",
       " 'место',\n",
       " 'прежде',\n",
       " 'взглядывать',\n",
       " 'казаться',\n",
       " 'должный',\n",
       " 'бояться',\n",
       " 'роща',\n",
       " 'трава',\n",
       " 'птичка',\n",
       " 'таить',\n",
       " 'щека',\n",
       " 'некоторый',\n",
       " 'правый',\n",
       " 'весна',\n",
       " 'чулок',\n",
       " 'эрастов',\n",
       " 'здешний']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.words_closer_than(\"лиза\", \"эраст\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры варьирования\n",
    "\n",
    "1) препроцессинг -- лемматизировать или нет, например, вдруг мы хотим посмотреть на морфологические пропорции? тогда лемматизировать не нужно\n",
    "\n",
    "2) размер корпуса -- чем больше, тем лучше, но! не для семантических задач -- для них важнее качество\n",
    "\n",
    "3) размер словаря\n",
    "\n",
    "4) negative samples\n",
    "\n",
    "5) количество итераций\n",
    "\n",
    "6) длина вектора -- 100-300 (судя по всему, >300 не сильно улучшает результаты)\n",
    "\n",
    "7) длина окна -- для синтаксических задач, примерно 4, для семантических задач, большое окно, 8, 10.\n",
    "\n",
    "Хорошая статья про сравнение моделей с варьированием параметров: https://www.aclweb.org/anthology/D14-1162.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как использовать готовую модель\n",
    "\n",
    "#### RusVectōrēs\n",
    "\n",
    "На сайте RusVectōrēs (https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятором семантической близости».\n",
    "\n",
    "Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "Ещё давайте посмотрим на **векторные романы** https://nevmenandr.github.io/novel2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Работа с моделью\n",
    "\n",
    "Модели word2vec бывают разных форматов:\n",
    "\n",
    "+ .vec.gz — обычный файл\n",
    "+ .bin.gz — бинарник\n",
    "\n",
    "Загружаются они с помощью одного и того же гласса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`.\n",
    "\n",
    "Если же эмбеддинги обучены не с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. для загрузки предобученных эмбеддингов `glove`, `fasttext`, `bpe` и любых других нужна именно она.\n",
    "\n",
    "Скачаем с RusVectōrēs модель для русского языка, обученную на НКРЯ образца 2015 г."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
       " <http.client.HTTPMessage at 0xb9c8748>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мини-исследование**: Давайте протестируем, выделяет ли модель функцию интенсификации в прилагательных? Например, *ужасный курильщик* может интерпретироваться как *человек, который много курит*, а не только как (не столько как) *очень плохой человек-курильщик*. Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных). NB! В названиях моделей на `rusvectores` указано, какой тегсет они используют (mystem, upos и т.д.)\n",
    "\n",
    "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хороший_A\n",
      "[ 0.00722357 -0.00361956  0.1272455   0.06584469  0.00709477 -0.02014845\n",
      " -0.02056034  0.01321563  0.13692418 -0.09624264]\n",
      "плохой_A 0.7463520765304565\n",
      "неплохой_A 0.6708558797836304\n",
      "отличный_A 0.6633436679840088\n",
      "превосходный_A 0.6079519987106323\n",
      "замечательный_A 0.586450457572937\n",
      "недурной_A 0.5322482585906982\n",
      "отменный_A 0.5168066024780273\n",
      "прекрасный_A 0.4982394576072693\n",
      "посредственный_A 0.49099433422088623\n",
      "приличный_A 0.48622459173202515\n",
      "\n",
      "\n",
      "плохой_A\n",
      "[-0.05218472  0.0307817   0.1459371   0.0151835   0.06219714  0.01153753\n",
      " -0.01169093  0.01818374  0.0955373  -0.10191503]\n",
      "хороший_A 0.7463520765304565\n",
      "дурной_A 0.6186875700950623\n",
      "скверный_A 0.6014161109924316\n",
      "отличный_A 0.5226833820343018\n",
      "посредственный_A 0.5061031579971313\n",
      "неважный_A 0.5021153092384338\n",
      "неплохой_A 0.49169063568115234\n",
      "никудышный_A 0.48035895824432373\n",
      "ухудшать_V 0.43680471181869507\n",
      "плохо_ADV 0.4314875304698944\n",
      "\n",
      "\n",
      "ужасный_A\n",
      "[-0.05553271 -0.03172469  0.01998607  0.00171507 -0.00935555 -0.0296017\n",
      "  0.05394973  0.01597532 -0.03785459 -0.02099892]\n",
      "страшный_A 0.8007249236106873\n",
      "жуткий_A 0.6982528567314148\n",
      "отвратительный_A 0.6798903942108154\n",
      "ужасающий_A 0.6174499988555908\n",
      "чудовищный_A 0.6100855469703674\n",
      "постыдный_A 0.6009703874588013\n",
      "невероятный_A 0.5827823281288147\n",
      "ужасать_V 0.5815353393554688\n",
      "кошмарный_A 0.5675789713859558\n",
      "позорный_A 0.5351496338844299\n",
      "\n",
      "\n",
      "жуткий_A\n",
      "[-0.07627533 -0.06143281 -0.02622319 -0.03769541 -0.00350412 -0.01479934\n",
      "  0.03325103  0.06712756 -0.0044996   0.0145266 ]\n",
      "ужасный_A 0.6982529163360596\n",
      "страшный_A 0.6917036771774292\n",
      "зловещий_A 0.6490103006362915\n",
      "странный_A 0.6009964942932129\n",
      "отвратительный_A 0.5856714248657227\n",
      "тоскливый_A 0.5783498287200928\n",
      "кошмарный_A 0.5670032501220703\n",
      "гнетущий_A 0.5607055425643921\n",
      "чудовищный_A 0.5550791621208191\n",
      "мрачный_A 0.5542315244674683\n",
      "\n",
      "\n",
      "страшный_A\n",
      "[-0.12759186 -0.0206753   0.00979353 -0.02963523  0.03109632  0.02121338\n",
      " -0.02869159  0.02574235 -0.02556899 -0.03742376]\n",
      "ужасный_A 0.800724983215332\n",
      "жуткий_A 0.6917036771774292\n",
      "чудовищный_A 0.5934231877326965\n",
      "кошмарный_A 0.5395629405975342\n",
      "отвратительный_A 0.5351147651672363\n",
      "невероятный_A 0.520784854888916\n",
      "ужасающий_A 0.5174920558929443\n",
      "зловещий_A 0.5163233280181885\n",
      "жестокий_A 0.5096044540405273\n",
      "ужасать_V 0.5071669816970825\n",
      "\n",
      "\n",
      "красный_A\n",
      "[ 0.01627072 -0.01136785 -0.00790482  0.02294072  0.05129128  0.10162549\n",
      "  0.07488654 -0.06475785 -0.0203686   0.09159683]\n",
      "алый_A 0.642128586769104\n",
      "малиновый_A 0.6113020777702332\n",
      "красная_S 0.5526680946350098\n",
      "желтый_A 0.5431625247001648\n",
      "оранжевый_A 0.5371882319450378\n",
      "трехцветный_A 0.531793475151062\n",
      "пунцовый_A 0.5125025510787964\n",
      "синий_A 0.5102002024650574\n",
      "фиолетовый_A 0.5072877407073975\n",
      "лиловый_A 0.5004072785377502\n",
      "\n",
      "\n",
      "синий_A\n",
      "[-0.00614284  0.04970241 -0.00461786 -0.11465221  0.08177482  0.00020589\n",
      "  0.04895581  0.02750725 -0.05211812  0.06006202]\n",
      "голубой_A 0.855513334274292\n",
      "темно-синий_A 0.7498061656951904\n",
      "оранжевый_A 0.7341035008430481\n",
      "лиловый_A 0.7314398288726807\n",
      "фиолетовый_A 0.7291390895843506\n",
      "желтый_A 0.7263568639755249\n",
      "ярко-синий_A 0.6990128755569458\n",
      "черный_A 0.6909208297729492\n",
      "зеленый_A 0.6799378395080566\n",
      "коричневый_A 0.6729934215545654\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? \n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print('Увы, слова \"%s\" нет в модели!' % word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим косинусную близость пары слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463521\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('плохой_A', 'хороший_A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12778336\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('плохой_A', 'синий_A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6982529\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('ужасный_A', 'жуткий_A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем составить пропорцию:\n",
    "\n",
    "+ positive — вектора, которые мы складываем\n",
    "+ negative — вектора, которые вычитаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "страшный_A\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['плохой_A', 'ужасный_A'], negative=['хороший_A'])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найди лишнее!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хороший_A\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('плохой_A хороший_A ужасный_A страшный_A'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "плохой_A\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('плохой_A ужасный_A страшный_A'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5575\tбезумно_ADV\n",
      "0.4791\tбезмерно_ADV\n",
      "0.4536\tжутко_ADV\n",
      "0.4472\tневероятно_ADV\n",
      "0.4394\tочень_ADV\n",
      "0.4364\tчертовски_ADV\n",
      "0.4231\tстрашно_ADV\n",
      "0.4124\tнеобычайно_ADV\n",
      "0.4119\tнестерпимо_ADV\n",
      "0.4005\tнеобыкновенно_ADV\n"
     ]
    }
   ],
   "source": [
    "for word, score in model.most_similar(positive=['ужасно_ADV'], negative=['плохой_A']):\n",
    "    print(f'{score:.4}\\t{word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что означают полученные результаты для нашего исследования? Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация\n",
    "\n",
    "Можно использовать разные методы того, как преобразовать векторы так, чтобы можно было их поместить на двумерное пространство, например, с помощью PCA. В зависимости от того, относительно какого набора слов вы пытаетесь найти оптимально отображение на двумерное пространство, у вас могут получаться разные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']\n",
    "X = model[words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На списке конкретных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На все словах в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(model[list(model.vocab)])\n",
    "coords = pca.transform(model[words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8VOW97/HPzwQsl4IKKBSBANoNmJBAA1EaIIhH7NEDRgGJAUHrRrFUt/YFqAkV8HCsFby19BSOu0bccUDRWEUEqgYiojWhDQIiNwmXIJZAhUKIXPKcP2aSnYRcJuTO+r5fL16Z9aznWfObeTHznfWsmbXMOYeIiHjTRQ1dgIiINByFgIiIhykEREQ8TCEgIuJhCgEREQ9TCIiIeJhCQKSWmdksM/uvhq5DJBgKAbngmdljZraiTNuOCtrG1W91Ig1LISBekAH81MxCAMysI9AM6F+m7apA36CYn15D0qTpP7B4QSb+N/2owPIQIB3YVqZtl3PugJkNMrNMMzsa+DuoaENmtsbM5prZJ0A+0MPMupvZWjP7l5n9BWhfov8PzOy/zOywmX0X2N4V9fCYRYKiEJALnnPuFPBX/G/0BP5+DKwr05ZhZpcB7wEvAu2AZ4H3zKxdiU1OACYDPwT2AK8BG/C/+T8JTCzRdyLQFugS2N79wMnafYQi508hIF6xlv9+wx+MPwQ+LtO2FrgZ2OGce9U5d8Y55wO+Av5XiW2lOOe2OOfOAJ2AAcBM59z3zrkM4N0SfU/jf/O/yjl31jm3wTl3rI4eo0i1KQTEKzKAWDO7FOjgnNsBrAcGBdrCA31+hP/TfUl7gM4llveVuP0j4J/OuRNl+hd5FVgFLDGzA2b2WzNrViuPSKQWKATEKz7FPy0zGfgEIPCJ/ECg7YBzbndguVuZsV2B3BLLJU+9+w1wqZm1KtOfwH2cds7Nds71AQYBtwB31cojEqkFCgHxBOfcSSALeAT/NFCRdYG2om8FrQB+bGZ3mlmomd0B9AGWV7DdPYHtzjaz5mYWS4mpIzMbZmYRgW8hHcM/PXS2dh+dyPlTCIiXrAUux//GX+TjQFsGgHPuMP5P678CDgPTgVucc3mVbPdOIAY4AjwBLC6xriOwDH8AbA3UoB+SSaNhuqiMiIh3aU9ARMTDFAIiIh6mEBAR8TCFgIiIh4U2dAFltW/f3oWFhTV0GSIiTcqGDRvynHMdqjuu0YVAWFgYWVlZDV2GiEiTYmZlf+keFE0HiYh4mEJARMTDFAIiIh6mEBAR8TCFgIiIhykEREQ8TCEgIuJhCgEREQ9TCIiIeJhCQETEwxQCIiIephAQEfEwhYCIiIcpBEREPEwhICLiYQoBEREPUwiIiHhYUCFgZjeZ2TYz22lmj5azfoiZ/c3MzpjZ6HLWtzGzXDP7fW0ULSIitaPKEDCzEGAB8DOgD5BgZn3KdNsLTAJeq2AzTwJrz79MERGpC8HsCQwEdjrnvnbOnQKWAKNKdnDO5TjnvgAKyw42s58AVwCra6FeERGpRcGEQGdgX4nl/YG2KpnZRcB8YFoV/SabWZaZZR06dCiYTYuISC0IJgSsnDYX5PYfAFY45/ZV1sk5t8g5F+2ci+7QoUOQmxYRkZoKDaLPfqBLieUrgQNBbv86YLCZPQC0Bpqb2XHn3DkHl0VEpP4FEwKZwNVm1h3IBcYBdwazcedcYtFtM5sERCsAREQajyqng5xzZ4CpwCpgK/C6c26Lmc0xs5EAZjbAzPYDY4CFZralLosWEZHaYc4FO71fP6Kjo11WVlZDlyEi0qSY2QbnXHR1x+kXwyIiHqYQEBHxMIWAiIiHKQRERDxMISAi4mEKAZFG5q677iI6OpoJEyYE1f+hhx6ic+fOFBaec+oukSoF82MxEalHixcvDrpvYWEhaWlpdOnShYyMDOLi4uquMLkgaU9AJGDfvn3069ePPXv2ANC6dWsAtm/fTnR0NFOmTOGFF14o7p+UlMSLL75IYmIiUVFRXHbZZXTv3p2oqCj++Mc/kpKSwtSpUwFYsmQJI0aM4PTp06Xat23bRmhoKMuWLQMgLCyMvLw8AMaPH094eHilNaenpxMeHs6UKVPw+Xy1+4SIJygExNtSUyEsDC66iC6DB/P/bruNsWPHcuzYMQAOHz7MnXfeyeLFi5kxYwavvPIK4P8EvmTJEhITE0lNTSU7O5uRI0fyzDPPkJ2dzf333198Fx9++CEvvPACy5Yto1mzZqXufubMmfTq1eucsjZt2sTmzZurLN/n85GQkEB8fDzLly/n9OnTNXgyxIsUAuJdqakweTLs2QPOwZ49RP/mN/S46CLuuOMOCgsLue222+jXrx99+vQhLCyMdu3a8fe//53Vq1fTr18/2rVrV+ldbNq0ifj4eKZPn84Pf/jDUus2bNhAYWEh0dHn/sgzOTmZ2bNnV7rtU6dOsWLFCm699VbatGlDTEwMq1frsh1SPQoB8a6kJMjPL9WUlZ/Pgb//nbi4OE6ePMmYMWP44osv+PLLLwG49957SUlJ4eWXX+aee+6p8i62bt3Ka6+9xhNPPEFBQUGpdcnJyTz55JPnjFm/fj2tW7cmMjKy0m2vXLmSo0ePEhERQVhYGOvWrdOUkFSbQkC8a+/eUouFwIPA77//nhkzZtCqVSumTp3Kiy++WDyHHx8fz8qVK8nMzGTEiBFV3sXYsWO55ZZbGD16NHPmzCluX7t2LZ06daJ3797njJk1a1apvhXx+Xy89NJL5OTkkJOTw+7du1m9ejX5ZYJNpDIKAfGurl1LLf4R/wUwIrp1K9UeExPDVVddxauvvkrz5s0ZNmwYY8eOJSQkJOi7euyxx3j//ff54osvANixYwezZs0qt29MTAw9e/asdHv5+fmsWrWKm2++ubitVatWxMbG8u677wZdl4jOIireVXRMoOQn55YtYdEiSEwsd0hhYSH9+/fnjTfe4Oqrr66nQkWqprOIilRXYqL/Db9bNzDz/60kAL788kuuuuoqhg8frgCQC4b2BEQauVWrVjFjxoxSbd27dyctLa2BKpLG6Hz3BBQCIiIXAE0HiYhItSkEREQ8TCEgIuJhCgEREQ9TCIiIeJhCQETEwxQCIiIephAQEfEwhYCIiIcpBEREPEwhICLiYQoBEREPUwiIiHiYQkBEpJH69ttvGT58OAMGDOC5554LaoyZbTSzoC82HXre1YmISJ264oor+PDDD4Pub2a98X+4H2JmrZxzJ6oaE9SegJndZGbbzGynmT1azvohZvY3MztjZqNLtEeZ2admtsXMvjCzO4J+NCIijdzixYvp27cvkZGRTJgwgUmTJrFs2TIAXnrpJcyMvLw8cnJyCA8PLx63bNkyJk2aBBDUmNOnT9OjRw+mTp1aVUl3Aq8Cq4GRwTyGKkPAzEKABcDPgD5Agpn1KdNtLzAJeK1Mez5wl3PuGuAm4HkzuySYwkREGqXUVAgLY4sZc3/+cz564AE2btzICy+8UNyloKCAP/7xj1x++eVBb7ayMYsWLaJ169bBbOYOYCngAxKCGRDMnsBAYKdz7mvn3ClgCTCqZAfnXI5z7gugsEz7dufcjsDtA8A/gA7BFCYi0uikpsLkybBnDx8Bo8+cof2vfgWpqVx22WXF3RYsWMDEiRNp0aJFcduuXbuIiooiKiqKadOmnbPp8sYA5Ofn8/LLLzNlypSqqmsJHHLO7QE+BPqb2aVVDQomBDoD+0os7w+0VYuZDQSaA7vKWTfZzLLMLOvQoUPV3bSISP1ISoL8fAAcYOBfTkoq7nLs2DF8Ph/33XdfqaE9e/YkOzub7OxsnnnmmVLrKhoD8PzzzzN58uRzwqEclwG9zCwH//tsG+D2qgYFEwJWTlu1LkxsZp3wz1Pd7ZwrLLveObfIORftnIvu0EE7CiLSSO3dW3xzOPA6cDjQfuTIEQCee+45HnzwQZo3bx70Zisac/ToUd5++23uueeeSscXFhaCPwT6OufCnHNh+GdsqpwSCubbQfuBLiWWrwQOBDEOADNrA7wHJDvnPgt2nIhIo9O1K+zZA8A1QBIwFAgJDaXfI48A4Jxj/Pjx1dpsRWP279/PvHnzCA2t/K06IyMD4JRzLrdkM9DHzDo5576paKw5V/mHejMLBbbjD75cIBO40zm3pZy+KcBy59yywHJz4H3gXefc85XeUUB0dLTLysoKpquISP0qOiYQmBICoGVLWLQIEhMbri7AzDY456KrO67K6SDn3BlgKrAK2Aq87pzbYmZzzGxk4M4HmNl+YAyw0MyKAmIsMASYZGbZgX9R1S1SRKRRSEz0v+F36wZm/r+NIABqoso9gfqmPQERkYrNnTuXN954o1TbmDFjSE5OPq89AYWAiMgFoM6mg0RE5MKlEBAR8TCFgIiIhykEREQ8TCEgIuJhCgEREQ9TCIiIeJhCQETEwxQCIiIephAQEfEwhYCIiIcpBEREPEwhICLiYQoBEREPUwiIiHiYQkBExMMUAiIiHqYQEBHxMIWAiIiHKQRERDxMISAi4mEKARERD1MIiIh4mEJARMTDFAIecNdddxEdHc2ECROC6v/QQw/RuXNnCgsL67gyEWlooQ1dgNS9xYsXB923sLCQtLQ0unTpQkZGBnFxcXVXmIg0OO0JBGnx4sX07duXyMhIJkyYQFRUFFFRUYSEhBTfPnDgAHFxcfzHf/wHgwYNIjw8nM8//xyAzz//nEGDBtGvXz8GDRrEtm3bAEhJSWHq1KkAZGVlFb/pnjlzhvbt2wOwZs0abrnlluJa5s2bx6xZswCIi4sjKyurVK1Tp04lJSUFgLCwMPLy8gAYP3484eHhlT7O9PR0wsPDmTJlCj6f7/yfMBFpErQnEIQtW7Ywd+5cPvnkE9q3b8+RI0e47LLLAGjdujXZ2dml+p84cYL169eTkZHBPffcw+bNm+nVqxcZGRmEhobywQcf8Pjjj/Pmm2/W22PYtGkTmzdvrrKfz+cjISGBUaNG8fjjj3P69GmaNWtWDxWKSEPQnkBlUlMhLIyPwsMZffAg7VetAigOgIokJCQAMGTIEI4dO8Z3333H0aNHGTNmDOHh4Tz88MNs2bKlWqV8/PHHxXsczz33XKl1iYmJREVFMXLkSP7xj3+UOz45OZnZs2dXeh+nTp1ixYoV3HrrrbRp04aYmBhWr15drTpFpGlRCFQkNRUmT4Y9e3CAHTvmX05NrXKomZ2zPHPmTIYNG8bmzZt59913KSgoqFY5gwcPJjs7m+zsbB5++OEypaaSnZ1N3759ef75588Zu379elq3bk1kZGSl97Fy5UqOHj1KREQEYWFhrFu3TlNCIhc4hUBFkpIgPx+A4cDrwOH8fEhK4siRI5UOXbp0KQDr1q2jbdu2tG3blqNHj9K5c2eA4vn62tauXTtOnTp1TvusWbOYM2dOleN9Ph8vvfQSOTk55OTksHv3blavXk1+4HkQkQuPjglUZO/e4pvXAEnAUCBkzx76PfJIpW/kl156KYMGDeLYsWP86U9/AmD69OlMnDiRZ599luuvv75U/7feeovs7GyOHz/O7t27iY2NrVap9957L61btwb8ewXPPPNMqfUxMTH07NmTnJycCreRn5/PqlWrWLhwYXFbq1atiI2N5d133+WOO+6oVk0i0jSYc67qTmY3AS8AIcBLzrnflFk/BHge6AuMc84tK7FuIpAcWPzfzrlXKruv6OhoV/bbLg0iLAz27Dm3vVs3qOTNNC4ujnnz5hEdHV1npYmIlGVmG5xz1X7jqXI6yMxCgAXAz4A+QIKZ9SnTbS8wCXitzNjLgCeAGGAg8ISZXVrdIhvE3LnQsmXptpYt/e0iIheIYKaDBgI7nXNfA5jZEmAU8GVRB+dcTmBd2Z+YjgD+4pw7Elj/F+AmoPEfbUxM9P9NSvJPDXXt6g+AovYKrFmzpu5rq6FVq1YxY8aMUm3du3cnLS2tgSoSkYYSTAh0BvaVWN6P/5N9MMob27lsJzObDEwG6Nq1a5CbrgeJiVW+6TdFI0aMYMSIEQ1dhog0AsF8O8jKaav6QEI1xjrnFjnnop1z0R06dAhy0yIiUlPBhMB+oEuJ5SuBA0FuvyZjRUSkjgUTApnA1WbW3cyaA+OAd4Lc/irgRjO7NHBA+MZAm4iINAJVhoBz7gwwFf+b91bgdefcFjObY2YjAcxsgJntB8YAC81sS2DsEeBJ/EGSCcwpOkgsIiINL6jfCdSnRvM7ARGRJqTOficgIiIXLoWAiIiHKQSkXFu2bGHw4MEMHDgwqDOJFl0E57HHHquH6kSktuiYgNSKFStWMHfuXA4ePMjOnTvPOZ22iNQtHRNoQmbOnMkLL7xQvJyUlMScOXMYMGAA3333HTk5OcWXgVy3bh2DBw/m5MmTHD9+nOHDh9O/f38iIiL485//XLyNspe/BJg0aRLLlhWfy4/w8PDi00SXd5nJojORlryc5ZEjR2jbti3z5s2r9DH5fD4eeughunbtymeffXaez4yI1DedSro+paZCUhI/37OH25o356H27SlMSGDJkiV8/vnn9O/fnzvuuIPf//73AHz99dc8+OCDrFixghYtWnDmzBnS0tJo06YNeXl5XHvttYwcOZIvv/zynMtf1pannnqKbt26Vdrn5MmTfPjhhyxcuJDvvvsOn8/HddddV2s1iEjd0Z5AfSlxpbIwoN2pU/z93ntZ/eij9OvXj3bt2nHLLbdw7NgxfvnLX3L8+HFuvvlmbr/9djp27AiAc47HH3+cvn37csMNN5Cbm8u3337LRx99xOjRo4svTF/y8pfTpk0rvizlrl27itt37dpV3D63gjOj5ubm8tlnnxEfH1/pQ1u+fDnDhg2jZcuW3H777aSlpXH27NmaPV8iUi8UAvWlxJXKAO4FUgoKeHnBAu655x7Af3GZHj160KNHD/bt28evf/1rlixZUnzd4NTUVA4dOsSGDRvIzs7miiuuoKCgAOdchXPwzzzzTPFlKXv27Fnc3rNnT7Kzs1m/fj2vvPIK27ZtO2fs7NmzmTlzZpXz+z6fjw8++ICwsDB+8pOfcPjwYdLT06v7DIlIA1AI1JcSVyoDiAdWApn5+YwYMYITJ07wxBNPMH/+fKZPn07v3r1JSEhg5syZTJs2DYCjR49y+eWX06xZM9LT09kTuOjN8OHDef311zl8+DBAtaaDWrRoQcuWLTl9+nSp9l27dpGTk8ONN95Y6fhjx46xbt069u7dW3y8YcGCBbo2sUgToRCoL2VOkd0cGAaMbdOGkJAQZs+ezeTJk4unfoqMHTuWb7/9loyMDBITE8nKyiI6OprU1FR69eoFwDXXXENSUhJDhw4lMjKSRx55pMpyii5jGR0dzZAhQ845UPzVV18FdV3it956i+uvv56LL764uG3UqFG88847fP/991WOF5GGpa+I1peiYwKBKaFCoL8ZbzzzDFf/6lcNW5uINHn6imhjl5gIixZBt258CVwVGsrwm25SAIhIg9KegATtF7/4BZ988kmptoceeoi77767gSoSkSLnuyeg3wlI0BYsWNDQJYhILdN0kIiIhykERMQT7rrrLqKjo4tPq1KVhx56iM6dO1NYWFjHlTUsTQeJiCcsXrw46L6FhYWkpaXRpUsXMjIyiIuLq7vCGpj2BESk1pQ8OeHWrVuJjIzk448/plevXkycOJG+ffsyevRo8gNflS46cWJ4eDiTJ0+m6IsqO3fu5IYbbiAyMpL+/fuza9euUic2BJg3bx6zZs0CIC4ujrJfKJk6dSopKSkAhIWFkZeXB8D48ePLPYFiSenp6YSHhzNlypQL/oePCgERqZnUVAgLg4sugthYOHqU3Nxcxo0bx2uvvUaXLl3Ytm0bkydP5osvvqBNmzb84Q9/APxv1JmZmWzevJmTJ0+yfPlyABITE/nFL37Bxo0bWb9+PZ06daqVUjdt2sTmzZur7Ofz+UhISCA+Pp7ly5ef84v6C4lCQETOX4kTI+Ic5OZyPDeXm669lri4OK655hoAunTpwk9/+lPA/0l83bp1gP8Td0xMDBEREXz00Uds2bKFf/3rX+Tm5hafuPAHP/gBLVu2BODjjz8uPvHhc889V6qUxMREoqKiGDlyZPH5tspKTk5m9uzZlT6kU6dOsWLFCm699VbatGlDTEwMq1evPv/nqJHTMQEROX9lTowIsM85Xi0o4Dfp6WzdupUWLVqccxJCM6OgoIAHHniArKwsunTpwqxZs4pPiFiRwYMHF+8tzJs3j+PHjxevS01NJTo6muTkZJ5//vlzxq5fv57WrVsTGRlZ6UNauXIlR48eJSIiAoD8/HxatmzJzTffXPlz0URpT0BEzl+ZEyMC9AbuPHyY3/3ud9x3330459i7dy+ffvop4J9qiY2NpaCgAID27dtz/Pjx4gsgtWnThiuvvJK3334bgO+//774GEIw2rVrx6lTp85pnzVrVlDnw/L5fLz00kvFJ0TcvXs3q1evrlYNTYlCQETOX5kTI5ZsHzp0KL169eL999+nd+/evPLKK/Tt25cjR44wZcoULrnkEv793/+diIgIbr31VgYMGFA8/NVXX+XFF1+kb9++DBo0iIMHD1ZZyr333ktsbCxvvvkmv/zlL89ZHxMTU+p06uXJz89n1apVpT71t2rVitjYWN59990qa2iKdNoIETl/ZU6MCEDLlv7zZCUmAv5vDN1yyy1BHZCV86cTyIlI/StxYkTM/H9LBIA0ftoTEBFPWrVqFTNmzCjV1r17d9LS0hqoopo53z0BhYCIyAVA00EiIlJtCgEREQ9TCIiIeJhCQETEwxQCIiIeFlQImNlNZrbNzHaa2aPlrL/YzJYG1v/VzMIC7c3M7BUz22RmW83ssdotX0REaqLKEDCzEGAB8DOgD5BgZn3KdPs58E/n3FXAc8DTgfYxwMXOuQjgJ8B9RQEhIiINL5g9gYHATufc1865U8ASYFSZPqOAVwK3lwHDzX/aQAe0MrNQoAVwCjhWK5WLiEiNBRMCnYF9JZb3B9rK7eOcOwMcBdrhD4QTwDfAXmCec+5I2Tsws8lmlmVmWYcOHar2gxARkfMTTAhYOW1lf2ZcUZ+BwFngR0B34Fdm1uOcjs4tcs5FO+eiO3ToEERJIiJSG4IJgf1AlxLLVwIHKuoTmPppCxwB7gRWOudOO+f+AXwCVPtnzVJz6enpXHfddVx77bWkp6dX2f/QoUM0a9aMhQsX1kN1ItJQggmBTOBqM+tuZs2BccA7Zfq8A0wM3B4NfOT8JyXaC1xvfq2Aa4Gvaqd0qY5hw4bx6aef8tlnnzFs2LAq+7/xxhtce+21F/xFtkW8rsoQCMzxTwVWAVuB151zW8xsjpmNDHT7T6Cdme0EHgGKvka6AGgNbMYfJi87576o5cfQZOTk5NCiRYvia6R2796dSZMmATBp0iS6d+9OVFQUzZs3Jy8vD+cc06ZNIzw8nIiICJYuXQpAWloaN9xwA845vvnmG3784x9z8OBBCgoKuPvuu4mIiKBfv37Fn/hTUlKYOnUqANu2bSM0NLT4Kk4V8fl8zJ8/n/3795Obm1t3T4qINKigrjHsnFsBrCjT9usStwvwfx207Ljj5bV7Wc+ePcnOzgZg2bJlxddLPXv2LPPnz+e2224jLCwMgLfeeovs7Gw2btxIXl4eAwYMYMiQIcTHx/Pmm2+yYMECVq5cyezZs+nYsSPz588HYNOmTXz11VfceOONbN++vdT9z5w5k169elVa4759+zh48CADBw5k7NixLF26lEceeaSWnwkRaQz0i+G6lpoKYWFw0UUQGwtHj5bb7eTJk/zgBz8o1bZu3ToSEhIICQnhiiuuYOjQoWRmZgLwu9/9jqeeeoqLL76YhISE4v4TJkwAoFevXnTr1q1UCGzYsIHCwkKioys/LLNkyRLGjh0LwLhx4zQlJHIBUwjUpaJL7+3ZA85Bbq7/X2rqOV0PHDjAj370o1JtlV3rITc3l4suuohvv/2WwsLCKvsDJCcn8+STT1ZZts/nIyUlhbCwMEaOHMnGjRvZsWNHleNEpOlRCNSlpKTS114FfxgkJZVq2rlzJzk5OfTpU/qH2EOGDGHp0qWcPXuWQ4cOkZGRwcCBAzlz5gx33303r732Gr179+bZZ58t7p8aCJjt27ezd+9e/u3f/g2AtWvX0qlTJ3r37l1pydu2bePEiRPk5uaSk5NDTk4Ojz32GEuWLKnJMyEijVRQxwTkPO3dW2X7gQMHGDVqFIsWLaJ58+alusXHx/Ppp58SGRmJmfHb3/6Wjh07MmfOHAYPHszgwYOJiopiwIAB3HzzzTzwwAPcf//9REREEBoaSkpKChdffDEAO3bs4L333quyZJ/PR3x8fKm222+/nXHjxjFz5sxqPgEi0tjp8pJ1KSzMPxVUVrdukJNT39WIyAVMl5dsjObOhZYtS7e1bOlvFxFpBDQdVJcSE/1/k5L8U0Bdu/oDoKi9gcXHx7N79+5SbU8//TQjRoxooIpEpL5pOkhE5AKg6SAREak2hYCIiIcpBEREPEwhICLiYQoBEREPUwiIiHiYQkBExMMUAiIiHqYQEBHxMIWAiIiHKQRERDxMISAi4mEKARERD1MIyAUhPT2d6667jmuvvZb09PQq+x86dIhmzZqxcOHCeqhOpPHSqaTFk/7whz/g8/kICQlhzZo1DV2OSI3pVNJSpzIzM+nbty8FBQWcOHGCa665hk2bNjFt2jTCw8OJiIhg6dKlAKxZs4YhQ4YQHx9Pnz59uP/++yksLAT81zCOiIggPDycGTNmFG+/devWxbfDw8PJCVx+c/z48SxfvhyAsLAw8vLyitvDw8MBSElJYerUqQBs27aN0NBQli1bVunj8fl8zJ8/n/3795Obm1sLz5BI06QQkMqlpkJYGANiYhi5Zw/Jt9/O9OnTGT9+PNu3byc7O5uNGzfywQcfMG3aNL755hsAPv/8c+bPn8+mTZvYtWsXb731FgcOHGDGjBl89NFHZGdnk5mZydtvv13tkjZt2sTmzZvLXTdz5kx69epV6fh9+/Zx8OBBBg4cyNixY4vDS8SLFAJSsdRUmDwZ9uwB5/j1sWP85f33yVq1iunTp7Nu3ToSEhJVbUn4AAAIfUlEQVQICQnhiiuuYOjQoWRmZgIwcOBAevToQUhICAkJCaxbt47MzEzi4uLo0KEDoaGhJCYmkpGRUe2ykpOTmT179jntGzZsoLCwkOjoyveIlyxZwtixYwEYN24cPp+v2jWIXCgUAlKxpCTIzy9ePAIcd45/7d1LQUEBlR1PMrNzlmvj+NP69etp3bo1kZGR56xLTk7mySefrHIbPp+PlJQUwsLCGDlyJBs3bmTHjh01rk2kKVIISMX27i21OBl4Ekg8fZoZM2YwZMgQli5dytmzZzl06BAZGRkMHDgQ8E8H7d69m8LCQpYuXUpsbCwxMTGsXbuWvLw8zp49i8/nY+jQodUqadasWcyZM+ec9rVr19KpUyd69+5d6fht27Zx4sQJcnNzycnJIScnh8cee4wlS5ZUqw6RC4VCQCrWtWvxzcVAKHAn8GjXrmRmZtK2bVv69u1LZGQk119/Pb/97W/p2LEjANdddx2PPvoo4eHhdO/enfj4eDp16sRTTz3FsGHDiIyMpH///owaNQqAkydPEhsbS2xsLLt372bMmDHExsayevXqUiXFxMTQs2fPc0rdsWMHs2bNqvIh+Xw+4uPjS7XdfvvtmhISz9JXRKViRccESkwJ0bIlLFoEiYkVDluzZg3z5s0r/laPiNQ9fUVUal9iov8Nv1s3MPP/rSIARKRp0Z6AXLDi4+PZvXt3qbann36aESNGNFBFInXnfPcEQoPc+E3AC0AI8JJz7jdl1l+Mf9r4J8Bh4A7nXE5gXV9gIdAGKAQGOOcKqluoSHWlpaU1dAkijV6V00FmFgIsAH4G9AESzKxPmW4/B/7pnLsKeA54OjA2FPgv4H7n3DVAHHC61qoXEZEaCeaYwEBgp3Pua+fcKWAJMKpMn1HAK4Hby4Dh5v+i+I3AF865jQDOucPOubO1U7qIiNRUMCHQGdhXYnl/oK3cPs65M8BRoB3wY8CZ2Soz+5uZTS/vDsxsspllmVnWoUOHqvsYRETkPAUTAlZOW9mjyRX1CQVigcTA33gzG35OR+cWOeeinXPRHTp0CKIkERGpDcGEwH6gS4nlK4EDFfUJHAdoi/8sA/uBtc65POdcPrAC6F/TokVEpHYEEwKZwNVm1t3MmgPjgHfK9HkHmBi4PRr4yPm/e7oK6GtmLQPhMBT4snZKFxGRmqryK6LOuTNmNhX/G3oI8Cfn3BYzmwNkOefeAf4TeNXMduLfAxgXGPtPM3sWf5A4YIVz7r06eiwiIlJN+rGYiMgFQKeNEBGRalMIiIh4mEJARMTDFAIiIh6mEBAR8TCFgIiIhykEREQ8TCEgIuJhCgEREQ9TCIiIeJhCQETEwxQCIiIephAQEfEwhYCIiIcpBEREPEwhICLiYQoBEREPUwiIiHiYQkBExMMUAiIiHqYQEBHxMIWAiIiHKQRERDxMISAi4mEKARERDzPnXEPXUIqZHQL21OFdtAfy6nD7dUm1N4ymXDs07fpVe/C6Oec6VHdQowuBumZmWc656Iau43yo9obRlGuHpl2/aq97mg4SEfEwhYCIiId5MQQWNXQBNaDaG0ZTrh2adv2qvY557piAiIj8Ny/uCYiISIBCQETEwy64EDCzy8zsL2a2I/D30nL6RJnZp2a2xcy+MLM7SqxLNbNtZrbZzP5kZs2aWP3dzeyvgfFLzax5Y6o90G+lmX1nZsvLtA83s7+ZWbaZrTOzq+qn8lqp3cxsrpltN7OtZvZg/VRe89pLrP+dmR2v22rLvd+aPvcN9pqthdob7PVa5IILAeBR4EPn3NXAh4HlsvKBu5xz1wA3Ac+b2SWBdalALyACaAHcW/cll1LT+p8GnguM/yfw83qouUgwtQM8A0wop/3/AonOuSjgNSC5TqosX01rnwR0AXo553oDS+qiyArUtHbMLBq4pLx19aCm9Tfka7amtTfk69XPOXdB/QO2AZ0CtzsB24IYsxG4upz2h4G5TaV+wPD/QjE00H4dsKox1g7EAcvLGR8TuP0Y8H+aUO2fA1fV5/+VWqw9BEgPjD3e1Oovs75eX7M1qb2hX69F/y7EPYErnHPfAAT+Xl5ZZzMbCDQHdpVpb4Y/uVfWUZ0VqUn97YDvnHNnAqv3A53rsNayqlV7Oe4FVpjZfvzP/W9qub7K1LT2nsAdZpZlZu+b2dW1XmHFalr7VOCdom00gJrWDzTYa7YmtTf06xWA0Pq+w9pgZh8AHctZlVTN7XQCXgUmOucKy6z+A5DhnPv4/Kqs9H7rpH4zs3K61ep3gGur9go8DPxP59xfzWwa8Cy1uGtfx7VfDBQ456LN7DbgT8DgWtguUHe1m9mPgDH4P6XWmTp+7ovUyWu2Dmuv89drMJpkCDjnbqhonZl9a2adnHPfBN4k/1FBvzbAe0Cyc+6zMuueADoA99Vi2cXqsP484BIzCw18urgSONDYaq9gbAcg0jn310DTUmr5E11d1R6wH3gzcDsNePk8yyxXHdbeD7gK2Bn4DNHSzHY652r1oHwdP/d1+pqtw9rr/PUajAtxOugdYGLg9kTgz2U7BI7ApwGLnXNvlFl3LzACSChn76A+nHf9zj+xmA6Mrmx8Haqy9kr8E2hrZj8OLP8PYGst1laVmtQO8DZwfeD2UGB7LdUVjPOu3Tn3nnOuo3MuzDkXBuTXdgAEoUbPfQO/Zmvy3Df067W4kAvqH/55tg+BHYG/lwXao4GXArfHA6eB7BL/ogLrzuCfXy9q/3UTq78H/oOUO4E3gIsbU+2B5Y+BQ8BJ/J+gRwTa44FN+A90rwF6NKHaL8G/Z7YJ+BT/Xk2TqL3MthriwHBNn/sGe83WQu0N9not+qfTRoiIeNiFOB0kIiJBUgiIiHiYQkBExMMUAiIiHqYQEBHxMIWAiIiHKQRERDzs/wPBxKrtmin7pgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка\n",
    "\n",
    "Это, конечно, хорошо, но как понять, какая модель лучше? Или вот, например, я сделал свою модель, а как понять, насколько она хорошая?\n",
    "\n",
    "Для этого существуют специальные датасеты для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии, а второй используется для оценки коэффициента семантической близости.\n",
    "\n",
    "#### Word Similarity\n",
    "\n",
    "Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \"представлениями\" людей.\n",
    "\n",
    "| слово 1    | слово 2    | близость |\n",
    "|------------|------------|----------|\n",
    "| кошка      | собака     | 0.7      | \n",
    "| чашка      | кружка     | 0.9      | \n",
    "\n",
    "Для каждой пары слов из заранее заданного датасета мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния о слова.\n",
    "\n",
    "#### Аналогии\n",
    "\n",
    "Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n",
    "\n",
    "В качестве слов-модификатор мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Датасет будет выглядеть следующм образом:\n",
    "\n",
    "| слово 1    | слово 2    | отношение     | \n",
    "|------------|------------|---------------|\n",
    "| Россия     | Москва     | страна-столица| \n",
    "| Норвегия   | Осло       | страна-столица|\n",
    "\n",
    "Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия) хотим получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой.\n",
    "\n",
    "Датасеты для русского языка можно скачать на странице с моделями на RusVectores. Посчитаем качество нашей модели НКРЯ на датасете про аналогии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.accuracy('ru_analogy_tagged.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in res[4]['incorrect'][:10]:\n",
    "    print('\\t'.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "\n",
    "+ Возьмите небольшой кусочек текста или стихотворение.\n",
    "+ Замените все неслужебные слова в нём на их ближайших соседей из нашей модели.\n",
    "+ Прокомментируйте результат.\n",
    "\n",
    "#### Задание 2\n",
    "\n",
    "+ Возьмите интересный Вам текст.\n",
    "+ Лемматизируйте текст, отчистите от пунктуации и служебной информации и обучите на нем модель word2vec (поэкспериментируйте с размером окна, с длиной вектора). \n",
    "+ Найдите по 5 ближайших слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы). Учтите, что слова может не быть в модели!\n",
    "+ Найдите по 5 \"далёких\" слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы).\n",
    "+ Прокомментируйте результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
