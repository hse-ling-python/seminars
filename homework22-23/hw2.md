## Домашнее задание 2

**Тема: векторные модели и TF-IDF**

**Дедлайн: 211, 212 TBD, 213: 8 ноября 23:59**

**Важное: работы принимаются строго в ipynb (не скрипт, не скрипт в ячейке ipynb)**

### Данные

1. Книги для обучения своей модели (см. п. 1)
2. Сайт rusvectores

Большая часть кода уже есть в конспектах, обращайтесь к ним.

### Задание

**1. на 2 балла**

**Word2Vec**
1. Возьмите несколько книг (например, с lib.ru) (от 10 книг), желательно, из одной серии или схожей тематики. 
2. Подготовьте тексты для обучения модели
    - лемматизируйте тексты
    - приведите к нижнему регистру
    - уберите знаки препинания
    - исключите стоп-слова (предлоги, местоимения и прочее)
    - запишите все тексты в один файл, каждое предложение на отдельной строке (для деления на предложения можно использовать sentence tokenizer из NLTK)

**2. + 4 балла: общая оценка до 6 баллов**

1. Обучите модель как показано в конспекте по word2vec с параметрами
  - размер вектора 300
  - минимальное количество вхождений 5
  - окно 5
  - количество итераций 50
2. Сколько слов оказалось в словаре? Это много или мало? 
3. Найдите ближайшие 10 слов для:
  - абстрактного понятия
  - имени героя
  - прилагательных хороший и плохой (или других антонимов)
4. Кратко результаты предыдущего пункта: 
  - насколько ожидаем такой результат? есть ли неожиданные соседи?
  - есть ли синонимы / антонимы в ближайших к слову?
  - говорит ли это что-то о самом корпусе? (есть какие особенности относительно языка в целом)
5. Найдите лишнее слово в ряду. Соответствует ли результат ожиданиям или модель ошиблась?

**3 + 2 балла: общая оценка до 8 баллов**

**3.1 W2V**
1. Скачайте и загрузите одну из Word2Vec моделей с сайта rusvectores
2. Придумайте какую-то свою семантическую пропорцию (Россия - Москва + Испания = Мадрид, король - мужчина + королева = женщина)
3. Попробуйте сделать визуализацию с помощью PCA (**один** из вариантов на выбор, можно предложить свой)
  - попробуйте на каких-то названиях предметов или животных: насколько это похоже на правду? 
  - попробуйте для абстрактных понятий (например, любовь-дружба-преданность-...)
  - попробуйте на многозначных словах: насколько результат соответствует Вашим ожиданиям?
4. Возьмите какое-нибудь предложение (не менее 10 слов) и замените все слова (которые не являются служебными) на ближайшие по векторам, можно просто в лемматизированном виде, потом просто вручную написать его, чтобы все согласовывалось.

**3.2 TF-IDF**
1. Возьмите статьи (20-100) из Википедии на разные темы (например, про города, страны, математику, историю, языки), подготовьте для построения TF-IDF (лемматизируйте)
2. Постройте TF-IDF для статей. Параметры от 1 до 3 слов, встретились минимум 3 раза.
3. Выделите для них ключевые слова, покажите их и оцените, насколько это соответствует их содержанию и вашим ожиданиям.
4. С помощью PCA визуализируйте TF-IDF вектора текстов (как в семантике, просто вместо семантических векторов tf-idf). Правда ли, что похожие тексты находятся рядом?

**4. + 2 балла: общая оценка до 10 баллов (продвинутый уровень)**

**TF-IDF**
1. Попробуйте разобраться с параметром token_pattern, как задать параметр так, чтобы числа не попадали в словарь?
2. Прочитайте про метрику cosine_similarity в sklearn. С помощью нее постройте матрицу схожести текстов на основе их векторов.
    - возьмите один из текстов и выведите тексты, которые наиболее на него похожи
3. Прочитайте про seaborn clustermap и попробуйте визуализировать матрицу близости.
    - подпишите названия текстов
    - посмотрите на то, как кластеризуются тексты, прокомментируйте, похоже ли это на адекватную оценку?

**Чек-лист**

1. Тетрадки с кодом
2. НЕ надо прикреплять вашу модель

Если у вас есть вопросы, задавайте в чате или пишите преподавателям


**Ссылки на GiHub Classroom:**

Группа 211

Группа 212

[Группа 213](https://classroom.github.com/a/ud6j3i_N)


